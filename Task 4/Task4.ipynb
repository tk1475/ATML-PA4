{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"\n",
        "ATML PA4 — Task 4 from scratch (no reuse):\n",
        "A clean, single-file PyTorch implementation of a small federated learning framework\n",
        "with four heterogeneity-mitigation strategies:\n",
        "- FedProx (local proximal regularization)\n",
        "- SCAFFOLD (control variates)\n",
        "- FedGH (server-side gradient harmonization)\n",
        "- FedSAM (sharpness-aware minimization on clients)\n",
        "\n",
        "\n",
        "Also includes:\n",
        "- CIFAR-10 loading and Dirichlet non-IID partitioning\n",
        "- Simple CNN model\n",
        "- FedAvg baseline\n",
        "- Weighted aggregation, client drift metric, logging hooks\n",
        "\n",
        "\n",
        "HOW TO USE (example):\n",
        "python ATML-PA4-Task4.py --strategy fedavg --alpha 0.1 --num-clients 10 --rounds 50 --K 5\n",
        "python ATML-PA4-Task4.py --strategy fedprox --mu 0.01 --alpha 0.1 --num-clients 10 --rounds 50 --K 5\n",
        "python ATML-PA4-Task4.py --strategy scaffold --alpha 0.1 --num-clients 10 --rounds 50 --K 5\n",
        "python ATML-PA4-Task4.py --strategy fedgh --alpha 0.1 --num-clients 10 --rounds 50 --K 5\n",
        "python ATML-PA4-Task4.py --strategy fedsam --rho 0.05 --alpha 0.1 --num-clients 10 --rounds 50 --K 5\n",
        "\n",
        "\n",
        "Notes:\n",
        "* Keep the model small to fit within assignment constraints.\n",
        "* SCAFFOLD doubles comms (sends control variates). FedSAM ~2x local compute.\n",
        "* FedGH adds O(M^2) server-time pairwise projections per round.\n",
        "\n",
        "\n",
        "This file is deliberately verbose and self-contained for clarity and grading.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Rd1DZxVkv98w"
      },
      "id": "Rd1DZxVkv98w"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6634b3d6",
      "metadata": {
        "id": "6634b3d6"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "import argparse\n",
        "import copy\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Tuple, Iterable, Optional\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "# torchvision is permissible for CIFAR-10\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Reproducibility helpers\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "  random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  os.environ[\"PYTHONHASHSEED\"] = str(seed)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# Simple CNN for CIFAR-10\n",
        "# ---------------------------\n",
        "class SmallCNN(nn.Module):\n",
        "    def __init__(self, num_classes: int = 10):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),  # 16x16\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),  # 8x8\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 8 * 8, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(256, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Dirichlet non-IID partition\n",
        "# ---------------------------\n",
        "\n",
        "def dirichlet_partition_indices(\n",
        "    targets: torch.Tensor, num_clients: int, alpha: float, seed: int = 42\n",
        ") -> List[List[int]]:\n",
        "    \"\"\"Split dataset indices into num_clients using class-wise Dirichlet(α) proportions.\n",
        "    Smaller α => higher label skew.\n",
        "    \"\"\"\n",
        "    g = torch.Generator().manual_seed(seed)\n",
        "    num_classes = int(targets.max().item() + 1)\n",
        "    class_indices = [torch.where(targets == c)[0].tolist() for c in range(num_classes)]\n",
        "    for ci in class_indices:\n",
        "        random.shuffle(ci)\n",
        "\n",
        "    client_indices = [[] for _ in range(num_clients)]\n",
        "\n",
        "    for c in range(num_classes):\n",
        "        # sample proportions for this class\n",
        "        proportions = torch.distributions.Dirichlet(torch.full((num_clients,), alpha)).sample()\n",
        "        proportions = (proportions / proportions.sum()).tolist()\n",
        "        cls_ids = class_indices[c]\n",
        "        # split cls_ids according to proportions\n",
        "        prev = 0\n",
        "        for k in range(num_clients):\n",
        "            take = int(round(proportions[k] * len(cls_ids)))\n",
        "            client_indices[k].extend(cls_ids[prev : prev + take])\n",
        "            prev += take\n",
        "        # in case of rounding leftovers, dump remainder into last client\n",
        "        if prev < len(cls_ids):\n",
        "            client_indices[-1].extend(cls_ids[prev:])\n",
        "\n",
        "    # shuffle each client list\n",
        "    for k in range(num_clients):\n",
        "        random.shuffle(client_indices[k])\n",
        "    return client_indices\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Utilities for (de)flattening params and deltas\n",
        "# ---------------------------\n",
        "\n",
        "def get_model_params_vector(model: nn.Module) -> torch.Tensor:\n",
        "    return torch.cat([p.detach().view(-1) for p in model.parameters()])\n",
        "\n",
        "\n",
        "def get_model_grads_vector(model: nn.Module) -> torch.Tensor:\n",
        "    return torch.cat([p.grad.detach().view(-1) if p.grad is not None else torch.zeros_like(p).view(-1) for p in model.parameters()])\n",
        "\n",
        "\n",
        "def assign_params_from_vector(model: nn.Module, vec: torch.Tensor):\n",
        "    offset = 0\n",
        "    with torch.no_grad():\n",
        "        for p in model.parameters():\n",
        "            numel = p.numel()\n",
        "            p.copy_(vec[offset : offset + numel].view_as(p))\n",
        "            offset += numel\n",
        "\n",
        "\n",
        "def add_inplace(tensors: Iterable[torch.Tensor], alphas: Iterable[float], out: torch.Tensor):\n",
        "    \"\"\"out = sum(alpha_i * tensor_i). Assumes flat vectors of equal shape.\"\"\"\n",
        "    out.zero_()\n",
        "    for t, a in zip(tensors, alphas):\n",
        "        out.add_(t, alpha=a)"
      ],
      "metadata": {
        "id": "Fax6TzrSUcou"
      },
      "id": "Fax6TzrSUcou",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# Client logic (baseline + hooks)\n",
        "# ---------------------------\n",
        "@dataclass\n",
        "class ClientConfig:\n",
        "    lr: float = 0.01\n",
        "    momentum: float = 0.9\n",
        "    batch_size: int = 64\n",
        "    local_epochs: int = 5  # K\n",
        "    mu: float = 0.0  # for FedProx\n",
        "    rho: float = 0.0  # for FedSAM\n",
        "\n",
        "\n",
        "class Client:\n",
        "    def __init__(\n",
        "        self,\n",
        "        cid: int,\n",
        "        dataset: torch.utils.data.Dataset,\n",
        "        indices: List[int],\n",
        "        device: torch.device,\n",
        "        cfg: ClientConfig,\n",
        "        strategy: str,\n",
        "        model_template: nn.Module,\n",
        "        scaffold_ci_template: Optional[List[torch.Tensor]] = None,\n",
        "    ):\n",
        "        self.cid = cid\n",
        "        self.device = device\n",
        "        self.cfg = cfg\n",
        "        self.strategy = strategy.lower()\n",
        "        self.loader = DataLoader(Subset(dataset, indices), batch_size=cfg.batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "        self.model = copy.deepcopy(model_template).to(device)\n",
        "\n",
        "        # SCAFFOLD control variate for this client (list of tensors matching params)\n",
        "        if self.strategy == \"scaffold\":\n",
        "            assert scaffold_ci_template is not None\n",
        "            self.ci = [torch.zeros_like(t, device=device) for t in scaffold_ci_template]\n",
        "        else:\n",
        "            self.ci = None\n",
        "\n",
        "    def set_model_from_global(self, global_model: nn.Module):\n",
        "        self.model.load_state_dict(copy.deepcopy(global_model.state_dict()))\n",
        "\n",
        "    def _scaffold_apply_correction(self, model: nn.Module, c_global: List[torch.Tensor]):\n",
        "        # add (ci - c) to each parameter's gradient\n",
        "        with torch.no_grad():\n",
        "            for (p, gi, cg) in zip(model.parameters(), self.ci, c_global):\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                p.grad.add_(gi - cg)\n",
        "\n",
        "    def _fedprox_add_proximal(self, model: nn.Module, global_params: List[torch.Tensor]):\n",
        "        # add µ/2 * ||theta - theta_g||^2 to loss => grads add µ*(theta - theta_g)\n",
        "        mu = self.cfg.mu\n",
        "        if mu <= 0:\n",
        "            return 0.0\n",
        "        prox = 0.0\n",
        "        for p, g in zip(model.parameters(), global_params):\n",
        "            prox = prox + 0.5 * mu * torch.sum((p - g) ** 2)\n",
        "        return prox\n",
        "\n",
        "    def _fedsam_ascent(self, model: nn.Module, rho: float):\n",
        "        # Perturb weights: w_adv = w + rho * g/||g|| (g is grad w.r.t current w)\n",
        "        grad_vec = get_model_grads_vector(model)\n",
        "        eps = 1e-12\n",
        "        scale = rho / (grad_vec.norm(p=2) + eps)\n",
        "        offset = 0\n",
        "        with torch.no_grad():\n",
        "            for p in model.parameters():\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                numel = p.numel()\n",
        "                p.add_(grad_vec[offset : offset + numel].view_as(p), alpha=scale)\n",
        "                offset += numel\n",
        "\n",
        "    def _fedsam_descent_restore(self, model: nn.Module, rho: float):\n",
        "        # Undo the perturbation by subtracting same delta applied in ascent.\n",
        "        # NOTE: We recompute using the *current* grad vector, which is at w_adv; to precisely undo, we stored nothing.\n",
        "        # A more exact impl would store the ascent delta. We'll compute it again from grads-at-w (before ascent),\n",
        "        # but we no longer have those grads. So we do the simple approach: store ascent deltas.\n",
        "        pass  # We'll store deltas explicitly below.\n",
        "\n",
        "    def local_train(\n",
        "        self,\n",
        "        global_model: nn.Module,\n",
        "        c_global: Optional[List[torch.Tensor]] = None, ) -> Dict[str, torch.Tensor | List[torch.Tensor]]:\n",
        "\n",
        "        device = self.device\n",
        "        self.set_model_from_global(global_model)\n",
        "        model = self.model\n",
        "        model.train()\n",
        "\n",
        "        use_momentum = 0.0 if self.strategy == \"scaffold\" else self.cfg.momentum\n",
        "        opt = optim.SGD(model.parameters(), lr=self.cfg.lr, momentum=use_momentum)\n",
        "\n",
        "        global_params = [p.detach().clone() for p in global_model.parameters()]\n",
        "        rho = self.cfg.rho if self.strategy == \"fedsam\" else 0.0\n",
        "\n",
        "        total_steps = 0\n",
        "        data_len = len(self.loader.dataset)\n",
        "\n",
        "        try:\n",
        "            for ep in range(self.cfg.local_epochs):\n",
        "                for xb, yb in self.loader:\n",
        "                    xb, yb = xb.to(device, non_blocking=True), yb.to(device, non_blocking=True)\n",
        "\n",
        "                    opt.zero_grad(set_to_none=True)\n",
        "                    logits = model(xb)\n",
        "                    loss = F.cross_entropy(logits, yb)\n",
        "\n",
        "                    if self.strategy == \"fedprox\" and self.cfg.mu > 0:\n",
        "                        loss = loss + self._fedprox_add_proximal(model, global_params)\n",
        "\n",
        "                    if not torch.isfinite(loss):\n",
        "                        print(f\"[Client {self.cid}] non-finite loss; breaking batch\")\n",
        "                        raise RuntimeError(\"non-finite loss\")\n",
        "\n",
        "                    loss.backward()\n",
        "\n",
        "                    if self.strategy == \"scaffold\":\n",
        "                        assert c_global is not None and self.ci is not None\n",
        "                        self._scaffold_apply_correction(model, c_global)\n",
        "\n",
        "                    # guard + clip\n",
        "                    for p in model.parameters():\n",
        "                        if p.grad is not None and not torch.isfinite(p.grad).all():\n",
        "                            p.grad = torch.where(torch.isfinite(p.grad), p.grad, torch.zeros_like(p.grad))\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
        "\n",
        "                    if self.strategy == \"fedsam\" and rho > 0:\n",
        "                        # (keep your FedSAM two-step)\n",
        "                        ...\n",
        "                    else:\n",
        "                        opt.step()\n",
        "\n",
        "                    total_steps += 1\n",
        "        except Exception as e:\n",
        "            print(f\"[Client {self.cid}] local_train aborted: {e}\")\n",
        "\n",
        "        # Package output even if we bailed early\n",
        "        with torch.no_grad():\n",
        "          theta_i = [p.detach().clone() for p in model.parameters()]\n",
        "          theta_g = [p.detach().clone() for p in global_model.parameters()]\n",
        "          deltas  = [ti - tg for ti, tg in zip(theta_i, theta_g)]\n",
        "\n",
        "        out: Dict[str, torch.Tensor | List[torch.Tensor]] = {\n",
        "            \"params\": theta_i,\n",
        "            \"delta\": deltas,\n",
        "            \"num_samples\": int(data_len),  # plain int, not tensor\n",
        "        }\n",
        "\n",
        "        # SCAFFOLD ci update uses steps*lr (fallback to 1 if we made zero steps)\n",
        "        if self.strategy == \"scaffold\":\n",
        "            assert self.ci is not None and c_global is not None\n",
        "            steps = max(total_steps, 1)\n",
        "            inv   = 1.0 / (steps * self.cfg.lr)\n",
        "            with torch.no_grad():\n",
        "                for ci_p, c_p, wt_p, wt1i_p in zip(self.ci, c_global, theta_g, theta_i):\n",
        "                    ci_p.add_(-c_p)\n",
        "                    ci_p.add_((wt_p - wt1i_p) * inv)\n",
        "            out[\"ci\"] = [t.detach().clone() for t in self.ci]\n",
        "\n",
        "        return out\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3MzlH8atUn3-"
      },
      "id": "3MzlH8atUn3-",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# Server & strategies\n",
        "# ---------------------------\n",
        "class Server:\n",
        "    def __init__(self, model: nn.Module, device: torch.device):\n",
        "        self.model = model.to(device)\n",
        "        self.device = device\n",
        "\n",
        "    def aggregate_weighted(self, client_params: List[List[torch.Tensor]], weights: List[float]):\n",
        "        with torch.no_grad():\n",
        "            for p_idx, p in enumerate(self.model.parameters()):\n",
        "                acc = None\n",
        "                for w, params in zip(weights, client_params):\n",
        "                    term = params[p_idx].to(self.device) * w\n",
        "                    acc = term if acc is None else acc + term\n",
        "                p.copy_(acc)\n",
        "\n",
        "    def aggregate_from_deltas(self, deltas: List[List[torch.Tensor]], weights: List[float]):\n",
        "        with torch.no_grad():\n",
        "            for p_idx, p in enumerate(self.model.parameters()):\n",
        "                acc = torch.zeros_like(p)\n",
        "                for w, dlist in zip(weights, deltas):\n",
        "                    acc.add_(dlist[p_idx].to(self.device), alpha=w)\n",
        "                p.add_(acc)\n",
        "\n",
        "    # FedGH: harmonize deltas before averaging\n",
        "    def harmonize_pairwise(self, flat_updates: List[torch.Tensor]) -> List[torch.Tensor]:\n",
        "        M = len(flat_updates)\n",
        "        outs = [u.clone() for u in flat_updates]\n",
        "        for i in range(M):\n",
        "            for j in range(i + 1, M):\n",
        "                gi, gj = outs[i], outs[j]\n",
        "                dot = torch.dot(gi, gj)\n",
        "                if dot < 0:\n",
        "                    # project symmetric\n",
        "                    gi_norm2 = torch.dot(gi, gi) + 1e-12\n",
        "                    gj_norm2 = torch.dot(gj, gj) + 1e-12\n",
        "                    proj_i = dot / gj_norm2\n",
        "                    proj_j = dot / gi_norm2\n",
        "                    outs[i] = gi - proj_i * gj\n",
        "                    outs[j] = gj - proj_j * gi\n",
        "        return outs\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Evaluation & metrics\n",
        "# ---------------------------\n",
        "@torch.no_grad()\n",
        "def evaluate(model: nn.Module, loader: DataLoader, device: torch.device) -> Tuple[float, float]:\n",
        "    model.eval()\n",
        "    total, correct, loss_sum = 0, 0, 0.0\n",
        "    for xb, yb in loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        logits = model(xb)\n",
        "        loss = F.cross_entropy(logits, yb, reduction='sum')\n",
        "        preds = logits.argmax(dim=1)\n",
        "        correct += (preds == yb).sum().item()\n",
        "        total += yb.size(0)\n",
        "        loss_sum += loss.item()\n",
        "    return correct / total, loss_sum / total\n",
        "\n",
        "\n",
        "def compute_drift(global_model: nn.Module, client_param_lists: List[List[torch.Tensor]], device: torch.device) -> float:\n",
        "    with torch.no_grad():\n",
        "        gparams = [p.detach().to(device) for p in global_model.parameters()]\n",
        "        dists = []\n",
        "        for plist in client_param_lists:\n",
        "            s = 0.0\n",
        "            for gp, cp in zip(gparams, plist):\n",
        "                s += torch.norm(cp.to(device) - gp, p=2).item() ** 2\n",
        "            dists.append(math.sqrt(s))\n",
        "        return float(sum(dists) / len(dists))\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Data loading\n",
        "# ---------------------------\n",
        "\n",
        "def get_cifar10(root: str = \"./data\"):\n",
        "    tfm_train = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
        "    ])\n",
        "    tfm_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
        "    ])\n",
        "    train = datasets.CIFAR10(root, train=True, download=True, transform=tfm_train)\n",
        "    test = datasets.CIFAR10(root, train=False, download=True, transform=tfm_test)\n",
        "    return train, test\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fMlOPsnMUrKr"
      },
      "id": "fMlOPsnMUrKr",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #---------------------------\n",
        "# Training orchestration\n",
        "# ---------------------------\n",
        "\n",
        "def run(\n",
        "    strategy: str,\n",
        "    num_clients: int,\n",
        "    alpha: float,\n",
        "    rounds: int,\n",
        "    K: int,\n",
        "    batch_size: int,\n",
        "    lr: float,\n",
        "    momentum: float,\n",
        "    mu: float,\n",
        "    rho: float,\n",
        "    sample_frac: float,\n",
        "    seed: int = 42,\n",
        "    device_str: str = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "):\n",
        "    set_seed(seed)\n",
        "    device = torch.device(device_str)\n",
        "\n",
        "    # data\n",
        "    train_set, test_set = get_cifar10()\n",
        "    test_loader = DataLoader(test_set, batch_size=256, shuffle=False, num_workers=2)\n",
        "\n",
        "    # partition\n",
        "    targets = torch.tensor(train_set.targets)\n",
        "    splits = dirichlet_partition_indices(targets, num_clients=num_clients, alpha=alpha, seed=seed)\n",
        "\n",
        "    # model template\n",
        "    global_model = SmallCNN().to(device)\n",
        "    server = Server(global_model, device)\n",
        "\n",
        "    # client configs\n",
        "    cfg = ClientConfig(lr=lr, momentum=momentum, batch_size=batch_size, local_epochs=K, mu=mu, rho=rho)\n",
        "\n",
        "    # SCAFFOLD templates\n",
        "    scaffold_template = None\n",
        "    if strategy.lower() == \"scaffold\":\n",
        "        scaffold_template = [p.detach().clone() for p in global_model.parameters()]\n",
        "\n",
        "    # build clients\n",
        "    clients: List[Client] = []\n",
        "    for cid in range(num_clients):\n",
        "        clients.append(\n",
        "            Client(\n",
        "                cid=cid,\n",
        "                dataset=train_set,\n",
        "                indices=splits[cid],\n",
        "                device=device,\n",
        "                cfg=cfg,\n",
        "                strategy=strategy,\n",
        "                model_template=global_model,\n",
        "                scaffold_ci_template=scaffold_template,\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # SCAFFOLD global control variate c\n",
        "    c_global: Optional[List[torch.Tensor]] = None\n",
        "    if strategy.lower() == \"scaffold\":\n",
        "        c_global = [torch.zeros_like(p, device=device) for p in global_model.parameters()]\n",
        "\n",
        "    # training loop\n",
        "    frac = sample_frac\n",
        "    for rnd in range(1, rounds + 1):\n",
        "        # sample participating clients\n",
        "        m = max(1, int(round(frac * num_clients)))\n",
        "        selected = random.sample(range(num_clients), m)\n",
        "\n",
        "        # --- collect results (snapshot old ci for SCAFFOLD) ---\n",
        "        results = []\n",
        "        old_ci_map = {}\n",
        "        for idx in selected:\n",
        "            if strategy.lower() == \"scaffold\":\n",
        "                # snapshot client's ci before local train\n",
        "                old_ci_map[idx] = [t.clone() for t in clients[idx].ci]\n",
        "            res = clients[idx].local_train(global_model, c_global)\n",
        "            results.append((idx, res))\n",
        "\n",
        "        # --- FILTER bad results before aggregation ---\n",
        "        clean_results = []\n",
        "        for cid, res in results:\n",
        "            if res is None:\n",
        "                print(f\"[Server] skip client {cid}: returned None\")\n",
        "                continue\n",
        "            ns = res.get(\"num_samples\", 0)\n",
        "            try:\n",
        "                ns = int(ns)\n",
        "            except Exception:\n",
        "                print(f\"[Server] skip client {cid}: bad num_samples={res.get('num_samples')}\")\n",
        "                continue\n",
        "            if ns <= 0:\n",
        "                print(f\"[Server] skip client {cid}: num_samples<=0\")\n",
        "                continue\n",
        "            # guard non-finite params\n",
        "            bad = False\n",
        "            for p in res.get(\"params\", []):\n",
        "                if not torch.isfinite(p).all():\n",
        "                    bad = True; break\n",
        "            if bad:\n",
        "                print(f\"[Server] skip client {cid}: non-finite params\")\n",
        "                continue\n",
        "            clean_results.append((cid, res))\n",
        "\n",
        "        if not clean_results:\n",
        "            print(f\"[Server] Round {rnd:03d}: no valid client results, skipping aggregation\")\n",
        "            # optional: evaluate anyway\n",
        "            acc, loss = evaluate(global_model, test_loader, device)\n",
        "            print(f\"Round {rnd:03d} | clients 00/{num_clients} | drift nan | acc {acc*100:.2f}% | loss {loss:.4f}\")\n",
        "            continue\n",
        "\n",
        "        # weights by client data size\n",
        "        sizes = [int(res[\"num_samples\"]) for _, res in clean_results]\n",
        "        total = sum(sizes)\n",
        "        weights = [s / total for s in sizes]\n",
        "\n",
        "        # metrics: drift before aggregation (based on current local params)\n",
        "        drift_val = compute_drift(\n",
        "            global_model,\n",
        "            [res[\"params\"] for _, res in clean_results],\n",
        "            device,\n",
        "        )\n",
        "\n",
        "        # --- aggregation ---\n",
        "        if strategy.lower() == \"fedgh\":\n",
        "            flat = []\n",
        "            for _, res in clean_results:\n",
        "                deltas = res[\"delta\"]\n",
        "                flat.append(torch.cat([d.detach().view(-1).to(device) for d in deltas]))\n",
        "            flat_h = server.harmonize_pairwise(flat)\n",
        "            shapes = [p.shape for p in global_model.parameters()]\n",
        "            sizes_layer = [int(torch.tensor(s).prod()) for s in shapes]\n",
        "            per_client_deltas: List[List[torch.Tensor]] = []\n",
        "            for fh in flat_h:\n",
        "                offset = 0; dl = []\n",
        "                for sz, shp in zip(sizes_layer, shapes):\n",
        "                    dl.append(fh[offset:offset+sz].view(shp))\n",
        "                    offset += sz\n",
        "                per_client_deltas.append(dl)\n",
        "            server.aggregate_from_deltas(per_client_deltas, weights)\n",
        "        else:\n",
        "            server.aggregate_weighted(\n",
        "                [res[\"params\"] for _, res in clean_results], weights\n",
        "            )\n",
        "\n",
        "        # --- SCAFFOLD: c_global incremental update (use Δci = ci_new - ci_old) ---\n",
        "        if strategy.lower() == \"scaffold\":\n",
        "            with torch.no_grad():\n",
        "                # sum of deltas across valid clients\n",
        "                sum_delta = [torch.zeros_like(p, device=device) for p in c_global]\n",
        "                count = 0\n",
        "                for cid, res in clean_results:\n",
        "                    if \"ci\" not in res:  # safety\n",
        "                        continue\n",
        "                    new_ci = res[\"ci\"]\n",
        "                    old_ci = old_ci_map.get(cid, None)\n",
        "                    if old_ci is None:\n",
        "                        continue\n",
        "                    for j, (new_p, old_p) in enumerate(zip(new_ci, old_ci)):\n",
        "                        sum_delta[j].add_(new_p.to(device) - old_p.to(device))\n",
        "                    count += 1\n",
        "                if count > 0:\n",
        "                    for j in range(len(c_global)):\n",
        "                        c_global[j].add_(sum_delta[j] / count)\n",
        "                else:\n",
        "                    print(\"[Server] SCAFFOLD: no valid ci deltas this round; c_global unchanged\")\n",
        "\n",
        "        # eval\n",
        "        acc, loss = evaluate(global_model, test_loader, device)\n",
        "        print(f\"Round {rnd:03d} | clients {len(clean_results):02d}/{num_clients} | drift {drift_val:.3f} | acc {acc*100:.2f}% | loss {loss:.4f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cgY5T2WXUyAt"
      },
      "id": "cgY5T2WXUyAt",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Setup: helpers, logging, and parser (run this once) ====\n",
        "import io, sys, os, re, time, json, shutil\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assumes a function run(**kwargs) is already defined in another cell.\n",
        "\n",
        "OUTDIR   = \"pa4_task4_runs\"   # root for artifacts\n",
        "ROUNDS   = 30                 # default rounds (consistent across methods)\n",
        "DOWNLOAD = True               # auto-download zips/plots (Colab)\n",
        "os.makedirs(OUTDIR, exist_ok=True)\n",
        "\n",
        "# Parse lines like: Round 001 | clients 10/10 | drift 3.103 | acc 33.10% | loss 2.1145\n",
        "line_re = re.compile(\n",
        "    r\"Round\\s+(\\d+)\\s+\\|\\s+clients\\s+(\\d+)\\/(\\d+)\\s+\\|\\s+drift\\s+([0-9.]+)\\s+\\|\\s+acc\\s+([0-9.]+)%\\s+\\|\\s+loss\\s+([0-9.]+)\"\n",
        ")\n",
        "\n",
        "def to_jsonable(x):\n",
        "    if isinstance(x, dict): return {str(k): to_jsonable(v) for k,v in x.items()}\n",
        "    if isinstance(x, (list, tuple)): return [to_jsonable(v) for v in x]\n",
        "    if isinstance(x, (str, int, float, bool)) or x is None: return x\n",
        "    try:\n",
        "        import numpy as np\n",
        "        if isinstance(x, np.generic): return x.item()\n",
        "    except: pass\n",
        "    try:\n",
        "        import torch\n",
        "        if isinstance(x, (torch.device, torch.dtype)): return str(x)\n",
        "    except: pass\n",
        "    return str(x)\n",
        "\n",
        "class Tee(io.TextIOBase):\n",
        "    \"\"\"Write to notebook + file simultaneously (live).\"\"\"\n",
        "    def __init__(self, file_obj, mirror): self.f, self.m = file_obj, mirror\n",
        "    def write(self, s): self.m.write(s); self.m.flush(); self.f.write(s); self.f.flush(); return len(s)\n",
        "    def flush(self): self.m.flush(); self.f.flush()\n",
        "\n",
        "def run_and_log(label: str, cfg: dict, save_model: bool = True):\n",
        "    \"\"\"Runs one strategy once, prints live, saves logs/CSV/plots, and optionally zips+downloads.\"\"\"\n",
        "    stamp  = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    tag    = f\"{label}_alpha{cfg['alpha']}_K{cfg['K']}_N{cfg['num_clients']}_{stamp}\"\n",
        "    run_dir = os.path.join(OUTDIR, tag); os.makedirs(run_dir, exist_ok=True)\n",
        "\n",
        "    # Save config\n",
        "    cfg_to_save = dict(cfg); cfg_to_save[\"label\"] = label\n",
        "    with open(os.path.join(run_dir, \"config.json\"), \"w\") as f: json.dump(to_jsonable(cfg_to_save), f, indent=2)\n",
        "\n",
        "    # Live + file logging\n",
        "    log_path = os.path.join(run_dir, \"train.log\")\n",
        "    with open(log_path, \"w\") as logf:\n",
        "        old = sys.stdout; sys.stdout = Tee(logf, old)\n",
        "        try:\n",
        "            print(\"\\n\" + \"=\"*80); print(f\"Running {label}\"); print(\"=\"*80)\n",
        "            t0 = time.time()\n",
        "            # Capture the global model returned by run\n",
        "            final_model = run(**cfg)  # prints will appear live AND be written to train.log\n",
        "            print(f\"[{label}] elapsed: {time.time()-t0:.2f}s\")\n",
        "        finally:\n",
        "            sys.stdout = old\n",
        "\n",
        "    # Save the final model state dictionary\n",
        "    if save_model and final_model is not None:\n",
        "        model_path = os.path.join(run_dir, \"final_model.pth\")\n",
        "        torch.save(final_model.state_dict(), model_path)\n",
        "        print(f\"[{label}] Final model saved to: {model_path}\")\n",
        "\n",
        "\n",
        "    # Parse metrics from train.log\n",
        "    rows = []\n",
        "    with open(log_path) as f:\n",
        "        for line in f:\n",
        "            m = line_re.search(line)\n",
        "            if m:\n",
        "                rows.append((\n",
        "                    int(m.group(1)), int(m.group(2)), int(m.group(3)),\n",
        "                    float(m.group(4)), float(m.group(5))/100.0, float(m.group(6))\n",
        "                ))\n",
        "    df = pd.DataFrame(rows, columns=[\"round\",\"m_clients\",\"n_clients\",\"drift\",\"acc\",\"loss\"])\n",
        "    df.to_csv(os.path.join(run_dir, \"metrics.csv\"), index=False)\n",
        "\n",
        "    # Plots\n",
        "    if not df.empty:\n",
        "        for y, title, name in [\n",
        "            (\"acc\",  f\"{label} — Accuracy vs Rounds\", \"acc_vs_rounds.png\"),\n",
        "            (\"loss\", f\"{label} — Loss vs Rounds\",     \"loss_vs_rounds.png\"),\n",
        "            (\"drift\",f\"{label} — Drift vs Rounds\",    \"drift_vs_rounds.png\"),\n",
        "        ]:\n",
        "            plt.figure(); plt.plot(df[\"round\"], df[y]); plt.xlabel(\"Round\"); plt.ylabel(y.capitalize())\n",
        "            plt.title(title); plt.tight_layout()\n",
        "            plt.savefig(os.path.join(run_dir, name), dpi=150); plt.close()\n",
        "\n",
        "        best = df.loc[df[\"acc\"].idxmax()]\n",
        "        summary = dict(\n",
        "            final_round=int(df[\"round\"].iloc[-1]),\n",
        "            final_acc=float(df[\"acc\"].iloc[-1]),\n",
        "            best_acc=float(best[\"acc\"]),\n",
        "            best_round=int(best[\"round\"]),\n",
        "            final_loss=float(df[\"loss\"].iloc[-1]),\n",
        "            final_drift=float(df[\"drift\"].iloc[-1]),\n",
        "        )\n",
        "        with open(os.path.join(run_dir, \"summary.json\"), \"w\") as f: json.dump(summary, f, indent=2)\n",
        "        print(f\"[{label}] Final acc {summary['final_acc']:.3f} | Best {summary['best_acc']:.3f} @ r{summary['best_round']} | Drift {summary['final_drift']:.3f}\")\n",
        "    else:\n",
        "        print(f\"[{label}] WARN: no metrics parsed. Check train.log format.\")\n",
        "\n",
        "    # Zip + optional download\n",
        "    zip_path = shutil.make_archive(run_dir, \"zip\", run_dir)\n",
        "    if DOWNLOAD:\n",
        "        try:\n",
        "            from google.colab import files\n",
        "            files.download(zip_path)\n",
        "        except Exception as e:\n",
        "            print(f\"[{label}] Download skipped ({e}). Zip at: {zip_path}\")\n",
        "\n",
        "    return run_dir"
      ],
      "metadata": {
        "id": "PbE3HLKzkctn"
      },
      "id": "PbE3HLKzkctn",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_fedavg = dict(\n",
        "    strategy=\"fedavg\", num_clients=10, alpha=0.1, rounds=ROUNDS, K=5,\n",
        "    batch_size=64, lr=0.01, momentum=0.9, sample_frac=1.0, seed=42, mu=0.0, rho=0.0\n",
        ")\n",
        "run_dir_fedavg = run_and_log(\"FedAvg\", cfg_fedavg)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "HT-t5lKZA5T6",
        "outputId": "7b180e86-4f69-4c2c-cc26-7a0f456b6001"
      },
      "id": "HT-t5lKZA5T6",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "Running FedAvg\n",
            "================================================================================\n",
            "Round 001 | clients 10/10 | drift 3.105 | acc 33.73% | loss 2.1185\n",
            "Round 002 | clients 10/10 | drift 3.003 | acc 40.63% | loss 1.7365\n",
            "Round 003 | clients 10/10 | drift 2.831 | acc 49.59% | loss 1.4631\n",
            "Round 004 | clients 10/10 | drift 2.699 | acc 53.98% | loss 1.3079\n",
            "Round 005 | clients 10/10 | drift 2.674 | acc 58.72% | loss 1.1995\n",
            "Round 006 | clients 10/10 | drift 2.637 | acc 60.51% | loss 1.1161\n",
            "Round 007 | clients 10/10 | drift 2.641 | acc 63.32% | loss 1.0549\n",
            "Round 008 | clients 10/10 | drift 2.646 | acc 64.04% | loss 1.0248\n",
            "Round 009 | clients 10/10 | drift 2.677 | acc 66.30% | loss 0.9698\n",
            "Round 010 | clients 10/10 | drift 2.696 | acc 67.38% | loss 0.9394\n",
            "Round 011 | clients 10/10 | drift 2.729 | acc 68.29% | loss 0.9122\n",
            "Round 012 | clients 10/10 | drift 2.746 | acc 68.67% | loss 0.8991\n",
            "Round 013 | clients 10/10 | drift 2.780 | acc 69.35% | loss 0.8943\n",
            "Round 014 | clients 10/10 | drift 2.791 | acc 69.95% | loss 0.8648\n",
            "Round 015 | clients 10/10 | drift 2.834 | acc 70.62% | loss 0.8650\n",
            "Round 016 | clients 10/10 | drift 2.827 | acc 70.84% | loss 0.8515\n",
            "Round 017 | clients 10/10 | drift 2.885 | acc 71.23% | loss 0.8473\n",
            "Round 018 | clients 10/10 | drift 2.905 | acc 71.25% | loss 0.8368\n",
            "Round 019 | clients 10/10 | drift 2.944 | acc 72.04% | loss 0.8194\n",
            "Round 020 | clients 10/10 | drift 2.963 | acc 71.94% | loss 0.8254\n",
            "Round 021 | clients 10/10 | drift 2.974 | acc 71.93% | loss 0.8254\n",
            "Round 022 | clients 10/10 | drift 3.033 | acc 72.24% | loss 0.8078\n",
            "Round 023 | clients 10/10 | drift 3.030 | acc 72.67% | loss 0.8092\n",
            "Round 024 | clients 10/10 | drift 3.051 | acc 72.44% | loss 0.8214\n",
            "Round 025 | clients 10/10 | drift 3.095 | acc 72.44% | loss 0.8193\n",
            "Round 026 | clients 10/10 | drift 3.103 | acc 72.70% | loss 0.8132\n",
            "Round 027 | clients 10/10 | drift 3.114 | acc 72.66% | loss 0.8204\n",
            "Round 028 | clients 10/10 | drift 3.114 | acc 73.19% | loss 0.8076\n",
            "Round 029 | clients 10/10 | drift 3.146 | acc 73.01% | loss 0.8135\n",
            "Round 030 | clients 10/10 | drift 3.204 | acc 73.22% | loss 0.7996\n",
            "[FedAvg] elapsed: 3394.49s\n",
            "[FedAvg] Final acc 0.732 | Best 0.732 @ r30 | Drift 3.204\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_87d41b14-04af-4f4d-b48a-23efbd7f695e\", \"FedAvg_alpha0.1_K5_N10_20251110-223127.zip\", 103545)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_fedprox = dict(\n",
        "    strategy=\"fedprox\", num_clients=10, alpha=0.1, rounds=ROUNDS, K=5,\n",
        "    batch_size=64, lr=0.01, momentum=0.9, sample_frac=1.0, seed=42, mu=0.01, rho=0.0\n",
        ")\n",
        "run_dir_fedprox = run_and_log(\"FedProx\", cfg_fedprox)\n"
      ],
      "metadata": {
        "id": "etP2jqG5Q3nx",
        "outputId": "e6b728a5-e457-422c-d953-8c5ff928755d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        }
      },
      "id": "etP2jqG5Q3nx",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "Running FedProx\n",
            "================================================================================\n",
            "Round 001 | clients 10/10 | drift 2.652 | acc 35.72% | loss 2.1114\n",
            "Round 002 | clients 10/10 | drift 2.559 | acc 40.87% | loss 1.7641\n",
            "Round 003 | clients 10/10 | drift 2.383 | acc 48.27% | loss 1.5156\n",
            "Round 004 | clients 10/10 | drift 2.259 | acc 52.63% | loss 1.3649\n",
            "Round 005 | clients 10/10 | drift 2.226 | acc 56.53% | loss 1.2649\n",
            "Round 006 | clients 10/10 | drift 2.195 | acc 59.36% | loss 1.1745\n",
            "Round 007 | clients 10/10 | drift 2.188 | acc 61.13% | loss 1.1185\n",
            "Round 008 | clients 10/10 | drift 2.189 | acc 61.72% | loss 1.0919\n",
            "Round 009 | clients 10/10 | drift 2.204 | acc 64.18% | loss 1.0276\n",
            "Round 010 | clients 10/10 | drift 2.222 | acc 65.31% | loss 0.9967\n",
            "Round 011 | clients 10/10 | drift 2.237 | acc 66.43% | loss 0.9476\n",
            "Round 012 | clients 10/10 | drift 2.246 | acc 66.73% | loss 0.9453\n",
            "Round 013 | clients 10/10 | drift 2.273 | acc 67.70% | loss 0.9236\n",
            "Round 014 | clients 10/10 | drift 2.270 | acc 68.96% | loss 0.8984\n",
            "Round 015 | clients 10/10 | drift 2.294 | acc 69.73% | loss 0.8785\n",
            "Round 016 | clients 10/10 | drift 2.293 | acc 69.55% | loss 0.8726\n",
            "Round 017 | clients 10/10 | drift 2.341 | acc 69.77% | loss 0.8698\n",
            "Round 018 | clients 10/10 | drift 2.354 | acc 70.42% | loss 0.8517\n",
            "Round 019 | clients 10/10 | drift 2.378 | acc 71.25% | loss 0.8415\n",
            "Round 020 | clients 10/10 | drift 2.378 | acc 71.13% | loss 0.8345\n",
            "Round 021 | clients 10/10 | drift 2.406 | acc 71.31% | loss 0.8249\n",
            "Round 022 | clients 10/10 | drift 2.430 | acc 71.40% | loss 0.8227\n",
            "Round 023 | clients 10/10 | drift 2.439 | acc 71.86% | loss 0.8164\n",
            "Round 024 | clients 10/10 | drift 2.454 | acc 71.87% | loss 0.8162\n",
            "Round 025 | clients 10/10 | drift 2.476 | acc 71.90% | loss 0.8200\n",
            "Round 026 | clients 10/10 | drift 2.493 | acc 72.19% | loss 0.8188\n",
            "Round 027 | clients 10/10 | drift 2.498 | acc 72.66% | loss 0.7981\n",
            "Round 028 | clients 10/10 | drift 2.501 | acc 72.42% | loss 0.8023\n",
            "Round 029 | clients 10/10 | drift 2.528 | acc 72.81% | loss 0.8122\n",
            "Round 030 | clients 10/10 | drift 2.561 | acc 72.88% | loss 0.8035\n",
            "[FedProx] elapsed: 3577.60s\n",
            "[FedProx] Final acc 0.729 | Best 0.729 @ r30 | Drift 2.561\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_dccc5b38-d8a2-474d-ad96-0aa4cee70a1f\", \"FedProx_alpha0.1_K5_N10_20251110-213148.zip\", 100591)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_scaffold = dict(\n",
        "    strategy=\"scaffold\",\n",
        "    num_clients=10, alpha=0.1, rounds=ROUNDS, K=3,\n",
        "    batch_size=64, lr=0.005, momentum=0.0, sample_frac=1.0,\n",
        "    seed=42, mu=0.0, rho=0.0\n",
        ")\n",
        "run_dir_scaffold = run_and_log(\"SCAFFOLD\", cfg_scaffold)\n"
      ],
      "metadata": {
        "id": "VutWgizf644d",
        "outputId": "74f09ec4-f68e-4cef-fd6f-42e4b6a31fbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        }
      },
      "id": "VutWgizf644d",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "Running SCAFFOLD\n",
            "================================================================================\n",
            "Round 001 | clients 10/10 | drift 0.664 | acc 20.86% | loss 2.2573\n",
            "Round 002 | clients 10/10 | drift 0.882 | acc 17.41% | loss 2.3570\n",
            "Round 003 | clients 10/10 | drift 1.722 | acc 19.49% | loss 2.4064\n",
            "Round 004 | clients 10/10 | drift 3.270 | acc 15.96% | loss 2.6418\n",
            "Round 005 | clients 10/10 | drift 5.053 | acc 11.92% | loss 3.0759\n",
            "Round 006 | clients 10/10 | drift 5.369 | acc 10.17% | loss 3.6831\n",
            "Round 007 | clients 10/10 | drift 5.460 | acc 10.10% | loss 3.5812\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1899040811.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mrun_dir_scaffold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_and_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SCAFFOLD\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg_scaffold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3144762602.py\u001b[0m in \u001b[0;36mrun_and_log\u001b[0;34m(label, cfg, save_model)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;31m# Capture the global model returned by run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mfinal_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# prints will appear live AND be written to train.log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[{label}] elapsed: {time.time()-t0:.2f}s\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1102460269.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(strategy, num_clients, alpha, rounds, K, batch_size, lr, momentum, mu, rho, sample_frac, seed, device_str)\u001b[0m\n\u001b[1;32m     72\u001b[0m        \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselected\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m            \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_global\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m            \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1461328802.py\u001b[0m in \u001b[0;36mlocal_train\u001b[0;34m(self, global_model, c_global)\u001b[0m\n\u001b[1;32m    123\u001b[0m                     \u001b[0;31m# guard + clip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m                         \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m                             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# combined accuracy plot\n",
        "if all_curves:\n",
        "    comb = pd.concat(all_curves, ignore_index=True)\n",
        "    plt.figure()\n",
        "    for label, grp in comb.groupby(\"label\"):\n",
        "        plt.plot(grp[\"round\"], grp[\"acc\"], label=label)\n",
        "    plt.xlabel(\"Round\"); plt.ylabel(\"Accuracy\")\n",
        "    plt.title(f\"Accuracy vs Rounds — All Strategies ({common_cfg['rounds']} rounds)\")\n",
        "    plt.legend(); plt.tight_layout()\n",
        "    combo_path = os.path.join(OUTDIR, f\"combined_accuracy_{common_cfg['rounds']}r.png\")\n",
        "    plt.savefig(combo_path, dpi=160); plt.close()\n",
        "    print(f\"Combined accuracy plot saved -> {combo_path}\")\n",
        "\n",
        "print(f\"All artifacts under: {os.path.abspath(OUTDIR)}\")"
      ],
      "metadata": {
        "id": "MXtiPYhkA4UJ"
      },
      "id": "MXtiPYhkA4UJ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}