{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"\n",
        "ATML PA4 — Task 4 from scratch (no reuse):\n",
        "A clean, single-file PyTorch implementation of a small federated learning framework\n",
        "with four heterogeneity-mitigation strategies:\n",
        "- FedProx (local proximal regularization)\n",
        "- SCAFFOLD (control variates)\n",
        "- FedGH (server-side gradient harmonization)\n",
        "- FedSAM (sharpness-aware minimization on clients)\n",
        "\n",
        "\n",
        "Also includes:\n",
        "- CIFAR-10 loading and Dirichlet non-IID partitioning\n",
        "- Simple CNN model\n",
        "- FedAvg baseline\n",
        "- Weighted aggregation, client drift metric, logging hooks\n",
        "\n",
        "\n",
        "HOW TO USE (example):\n",
        "python ATML-PA4-Task4.py --strategy fedavg --alpha 0.1 --num-clients 10 --rounds 50 --K 5\n",
        "python ATML-PA4-Task4.py --strategy fedprox --mu 0.01 --alpha 0.1 --num-clients 10 --rounds 50 --K 5\n",
        "python ATML-PA4-Task4.py --strategy scaffold --alpha 0.1 --num-clients 10 --rounds 50 --K 5\n",
        "python ATML-PA4-Task4.py --strategy fedgh --alpha 0.1 --num-clients 10 --rounds 50 --K 5\n",
        "python ATML-PA4-Task4.py --strategy fedsam --rho 0.05 --alpha 0.1 --num-clients 10 --rounds 50 --K 5\n",
        "\n",
        "\n",
        "Notes:\n",
        "* Keep the model small to fit within assignment constraints.\n",
        "* SCAFFOLD doubles comms (sends control variates). FedSAM ~2x local compute.\n",
        "* FedGH adds O(M^2) server-time pairwise projections per round.\n",
        "\n",
        "\n",
        "This file is deliberately verbose and self-contained for clarity and grading.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Rd1DZxVkv98w"
      },
      "id": "Rd1DZxVkv98w"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "6634b3d6",
      "metadata": {
        "id": "6634b3d6"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "import argparse\n",
        "import copy\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Tuple, Iterable, Optional\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "# torchvision is permissible for CIFAR-10\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Reproducibility helpers\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "  random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  os.environ[\"PYTHONHASHSEED\"] = str(seed)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# Simple CNN for CIFAR-10\n",
        "# ---------------------------\n",
        "class SmallCNN(nn.Module):\n",
        "    def __init__(self, num_classes: int = 10):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),  # 16x16\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),  # 8x8\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 8 * 8, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(256, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Dirichlet non-IID partition\n",
        "# ---------------------------\n",
        "\n",
        "def dirichlet_partition_indices(\n",
        "    targets: torch.Tensor, num_clients: int, alpha: float, seed: int = 42\n",
        ") -> List[List[int]]:\n",
        "    \"\"\"Split dataset indices into num_clients using class-wise Dirichlet(α) proportions.\n",
        "    Smaller α => higher label skew.\n",
        "    \"\"\"\n",
        "    g = torch.Generator().manual_seed(seed)\n",
        "    num_classes = int(targets.max().item() + 1)\n",
        "    class_indices = [torch.where(targets == c)[0].tolist() for c in range(num_classes)]\n",
        "    for ci in class_indices:\n",
        "        random.shuffle(ci)\n",
        "\n",
        "    client_indices = [[] for _ in range(num_clients)]\n",
        "\n",
        "    for c in range(num_classes):\n",
        "        # sample proportions for this class\n",
        "        proportions = torch.distributions.Dirichlet(torch.full((num_clients,), alpha)).sample()\n",
        "        proportions = (proportions / proportions.sum()).tolist()\n",
        "        cls_ids = class_indices[c]\n",
        "        # split cls_ids according to proportions\n",
        "        prev = 0\n",
        "        for k in range(num_clients):\n",
        "            take = int(round(proportions[k] * len(cls_ids)))\n",
        "            client_indices[k].extend(cls_ids[prev : prev + take])\n",
        "            prev += take\n",
        "        # in case of rounding leftovers, dump remainder into last client\n",
        "        if prev < len(cls_ids):\n",
        "            client_indices[-1].extend(cls_ids[prev:])\n",
        "\n",
        "    # shuffle each client list\n",
        "    for k in range(num_clients):\n",
        "        random.shuffle(client_indices[k])\n",
        "    return client_indices\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Utilities for (de)flattening params and deltas\n",
        "# ---------------------------\n",
        "\n",
        "def get_model_params_vector(model: nn.Module) -> torch.Tensor:\n",
        "    return torch.cat([p.detach().view(-1) for p in model.parameters()])\n",
        "\n",
        "\n",
        "def get_model_grads_vector(model: nn.Module) -> torch.Tensor:\n",
        "    return torch.cat([p.grad.detach().view(-1) if p.grad is not None else torch.zeros_like(p).view(-1) for p in model.parameters()])\n",
        "\n",
        "\n",
        "def assign_params_from_vector(model: nn.Module, vec: torch.Tensor):\n",
        "    offset = 0\n",
        "    with torch.no_grad():\n",
        "        for p in model.parameters():\n",
        "            numel = p.numel()\n",
        "            p.copy_(vec[offset : offset + numel].view_as(p))\n",
        "            offset += numel\n",
        "\n",
        "\n",
        "def add_inplace(tensors: Iterable[torch.Tensor], alphas: Iterable[float], out: torch.Tensor):\n",
        "    \"\"\"out = sum(alpha_i * tensor_i). Assumes flat vectors of equal shape.\"\"\"\n",
        "    out.zero_()\n",
        "    for t, a in zip(tensors, alphas):\n",
        "        out.add_(t, alpha=a)"
      ],
      "metadata": {
        "id": "Fax6TzrSUcou"
      },
      "id": "Fax6TzrSUcou",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# Client logic (baseline + hooks)\n",
        "# ---------------------------\n",
        "@dataclass\n",
        "class ClientConfig:\n",
        "    lr: float = 0.01\n",
        "    momentum: float = 0.9\n",
        "    batch_size: int = 64\n",
        "    local_epochs: int = 5  # K\n",
        "    mu: float = 0.0  # for FedProx\n",
        "    rho: float = 0.0  # for FedSAM\n",
        "\n",
        "\n",
        "class Client:\n",
        "    def __init__(\n",
        "        self,\n",
        "        cid: int,\n",
        "        dataset: torch.utils.data.Dataset,\n",
        "        indices: List[int],\n",
        "        device: torch.device,\n",
        "        cfg: ClientConfig,\n",
        "        strategy: str,\n",
        "        model_template: nn.Module,\n",
        "        scaffold_ci_template: Optional[List[torch.Tensor]] = None,\n",
        "    ):\n",
        "        self.cid = cid\n",
        "        self.device = device\n",
        "        self.cfg = cfg\n",
        "        self.strategy = strategy.lower()\n",
        "        self.loader = DataLoader(Subset(dataset, indices), batch_size=cfg.batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "        self.model = copy.deepcopy(model_template).to(device)\n",
        "\n",
        "        # SCAFFOLD control variate for this client (list of tensors matching params)\n",
        "        if self.strategy == \"scaffold\":\n",
        "            assert scaffold_ci_template is not None\n",
        "            self.ci = [torch.zeros_like(t, device=device) for t in scaffold_ci_template]\n",
        "        else:\n",
        "            self.ci = None\n",
        "\n",
        "    def set_model_from_global(self, global_model: nn.Module):\n",
        "        self.model.load_state_dict(copy.deepcopy(global_model.state_dict()))\n",
        "\n",
        "    def _scaffold_apply_correction(self, model: nn.Module, c_global: List[torch.Tensor]):\n",
        "        # add (ci - c) to each parameter's gradient\n",
        "        with torch.no_grad():\n",
        "            for (p, gi, cg) in zip(model.parameters(), self.ci, c_global):\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                p.grad.add_(gi - cg)\n",
        "\n",
        "    def _fedprox_add_proximal(self, model: nn.Module, global_params: List[torch.Tensor]):\n",
        "        # add µ/2 * ||theta - theta_g||^2 to loss => grads add µ*(theta - theta_g)\n",
        "        mu = self.cfg.mu\n",
        "        if mu <= 0:\n",
        "            return 0.0\n",
        "        prox = 0.0\n",
        "        for p, g in zip(model.parameters(), global_params):\n",
        "            prox = prox + 0.5 * mu * torch.sum((p - g) ** 2)\n",
        "        return prox\n",
        "\n",
        "    def _fedsam_ascent(self, model: nn.Module, rho: float):\n",
        "        # Perturb weights: w_adv = w + rho * g/||g|| (g is grad w.r.t current w)\n",
        "        grad_vec = get_model_grads_vector(model)\n",
        "        eps = 1e-12\n",
        "        scale = rho / (grad_vec.norm(p=2) + eps)\n",
        "        offset = 0\n",
        "        with torch.no_grad():\n",
        "            for p in model.parameters():\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                numel = p.numel()\n",
        "                p.add_(grad_vec[offset : offset + numel].view_as(p), alpha=scale)\n",
        "                offset += numel\n",
        "\n",
        "    def _fedsam_descent_restore(self, model: nn.Module, rho: float):\n",
        "        # Undo the perturbation by subtracting same delta applied in ascent.\n",
        "        # NOTE: We recompute using the *current* grad vector, which is at w_adv; to precisely undo, we stored nothing.\n",
        "        # A more exact impl would store the ascent delta. We'll compute it again from grads-at-w (before ascent),\n",
        "        # but we no longer have those grads. So we do the simple approach: store ascent deltas.\n",
        "        pass  # We'll store deltas explicitly below.\n",
        "\n",
        "    def local_train(\n",
        "        self,\n",
        "        global_model: nn.Module,\n",
        "        c_global: Optional[List[torch.Tensor]] = None,\n",
        "    ) -> Dict[str, torch.Tensor | List[torch.Tensor]]:\n",
        "        device = self.device\n",
        "        self.set_model_from_global(global_model)\n",
        "        model = self.model\n",
        "        model.train()\n",
        "        opt = optim.SGD(model.parameters(), lr=self.cfg.lr, momentum=self.cfg.momentum)\n",
        "\n",
        "        # cache global params for FedProx gradient contribution\n",
        "        global_params = [p.detach().clone() for p in global_model.parameters()]\n",
        "\n",
        "        rho = self.cfg.rho if self.strategy == \"fedsam\" else 0.0\n",
        "\n",
        "        for ep in range(self.cfg.local_epochs):\n",
        "            for xb, yb in self.loader:\n",
        "                xb, yb = xb.to(device, non_blocking=True), yb.to(device, non_blocking=True)\n",
        "\n",
        "                if not torch.isfinite(loss):\n",
        "                  print(f\"[Client {self.cid}] non-finite loss; breaking batch\")\n",
        "                  break\n",
        "\n",
        "                # ----- standard forward/backward -----\n",
        "                opt.zero_grad(set_to_none=True)\n",
        "                logits = model(xb)\n",
        "                loss = F.cross_entropy(logits, yb)\n",
        "\n",
        "                # FedProx proximal term\n",
        "                if self.strategy == \"fedprox\" and self.cfg.mu > 0:\n",
        "                    loss = loss + self._fedprox_add_proximal(model, global_params)\n",
        "\n",
        "                loss.backward()\n",
        "\n",
        "                # SCAFFOLD gradient correction\n",
        "                if self.strategy == \"scaffold\":\n",
        "                    assert c_global is not None and self.ci is not None\n",
        "                    self._scaffold_apply_correction(model, c_global)\n",
        "\n",
        "                # FedSAM two-step\n",
        "                if self.strategy == \"fedsam\" and rho > 0:\n",
        "                    # store ascent deltas\n",
        "                    ascent_deltas = []\n",
        "                    with torch.no_grad():\n",
        "                        grad_vec = get_model_grads_vector(model)\n",
        "                        eps = 1e-12\n",
        "                        scale = rho / (grad_vec.norm(p=2) + eps)\n",
        "                        offset = 0\n",
        "                        for p in model.parameters():\n",
        "                            if p.grad is None:\n",
        "                                ascent_deltas.append(None)\n",
        "                                continue\n",
        "                            numel = p.numel()\n",
        "                            delta = grad_vec[offset : offset + numel].view_as(p) * scale\n",
        "                            p.add_(delta)\n",
        "                            ascent_deltas.append(delta)\n",
        "                            offset += numel\n",
        "\n",
        "                    # compute grad at perturbed weights\n",
        "                    opt.zero_grad(set_to_none=True)\n",
        "                    logits_adv = model(xb)\n",
        "                    loss_adv = F.cross_entropy(logits_adv, yb)\n",
        "                    loss_adv.backward()\n",
        "\n",
        "                    # restore original weights\n",
        "                    with torch.no_grad():\n",
        "                        for p, delta in zip(model.parameters(), ascent_deltas):\n",
        "                            if delta is not None:\n",
        "                                p.sub_(delta)\n",
        "\n",
        "                    # now apply optimizer step using grads at w_adv (stored on params)\n",
        "                    opt.step()\n",
        "                else:\n",
        "                    # vanilla or FedProx/SCAFFOLD (after correction)\n",
        "                    opt.step()\n",
        "\n",
        "        # return results\n",
        "        with torch.no_grad():\n",
        "            theta_i = [p.detach().clone() for p in model.parameters()]\n",
        "            theta_g = [p.detach().clone() for p in global_model.parameters()]\n",
        "            # update delta for aggregation\n",
        "            deltas = [ti - tg for ti, tg in zip(theta_i, theta_g)]\n",
        "\n",
        "        out: Dict[str, torch.Tensor | List[torch.Tensor]] = {\n",
        "            \"params\": theta_i,\n",
        "            \"delta\": deltas,\n",
        "            \"num_samples\": torch.tensor(len(self.loader.dataset), dtype=torch.long),\n",
        "        }\n",
        "\n",
        "        # SCAFFOLD: update ci based on global and local change\n",
        "        if self.strategy == \"scaffold\":\n",
        "            assert self.ci is not None and c_global is not None\n",
        "            K = self.cfg.local_epochs\n",
        "            lr = self.cfg.lr\n",
        "            inv = 1.0 / (K * lr)\n",
        "            with torch.no_grad():\n",
        "                for ci_p, c_p, wt_p, wt1i_p in zip(self.ci, c_global, theta_g, theta_i):\n",
        "                    ci_p.add_(-c_p)                          # ci = ci - c\n",
        "                    ci_p.add_((wt_p - wt1i_p) * inv)         # + (w_t - w_{t+1}^i)/(K*lr)\n",
        "            out[\"ci\"] = [t.detach().clone() for t in self.ci]\n",
        "\n",
        "        return out\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3MzlH8atUn3-"
      },
      "id": "3MzlH8atUn3-",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# Server & strategies\n",
        "# ---------------------------\n",
        "class Server:\n",
        "    def __init__(self, model: nn.Module, device: torch.device):\n",
        "        self.model = model.to(device)\n",
        "        self.device = device\n",
        "\n",
        "    def aggregate_weighted(self, client_params: List[List[torch.Tensor]], weights: List[float]):\n",
        "        with torch.no_grad():\n",
        "            for p_idx, p in enumerate(self.model.parameters()):\n",
        "                acc = None\n",
        "                for w, params in zip(weights, client_params):\n",
        "                    term = params[p_idx].to(self.device) * w\n",
        "                    acc = term if acc is None else acc + term\n",
        "                p.copy_(acc)\n",
        "\n",
        "    def aggregate_from_deltas(self, deltas: List[List[torch.Tensor]], weights: List[float]):\n",
        "        with torch.no_grad():\n",
        "            for p_idx, p in enumerate(self.model.parameters()):\n",
        "                acc = torch.zeros_like(p)\n",
        "                for w, dlist in zip(weights, deltas):\n",
        "                    acc.add_(dlist[p_idx].to(self.device), alpha=w)\n",
        "                p.add_(acc)\n",
        "\n",
        "    # FedGH: harmonize deltas before averaging\n",
        "    def harmonize_pairwise(self, flat_updates: List[torch.Tensor]) -> List[torch.Tensor]:\n",
        "        M = len(flat_updates)\n",
        "        outs = [u.clone() for u in flat_updates]\n",
        "        for i in range(M):\n",
        "            for j in range(i + 1, M):\n",
        "                gi, gj = outs[i], outs[j]\n",
        "                dot = torch.dot(gi, gj)\n",
        "                if dot < 0:\n",
        "                    # project symmetric\n",
        "                    gi_norm2 = torch.dot(gi, gi) + 1e-12\n",
        "                    gj_norm2 = torch.dot(gj, gj) + 1e-12\n",
        "                    proj_i = dot / gj_norm2\n",
        "                    proj_j = dot / gi_norm2\n",
        "                    outs[i] = gi - proj_i * gj\n",
        "                    outs[j] = gj - proj_j * gi\n",
        "        return outs\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Evaluation & metrics\n",
        "# ---------------------------\n",
        "@torch.no_grad()\n",
        "def evaluate(model: nn.Module, loader: DataLoader, device: torch.device) -> Tuple[float, float]:\n",
        "    model.eval()\n",
        "    total, correct, loss_sum = 0, 0, 0.0\n",
        "    for xb, yb in loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        logits = model(xb)\n",
        "        loss = F.cross_entropy(logits, yb, reduction='sum')\n",
        "        preds = logits.argmax(dim=1)\n",
        "        correct += (preds == yb).sum().item()\n",
        "        total += yb.size(0)\n",
        "        loss_sum += loss.item()\n",
        "    return correct / total, loss_sum / total\n",
        "\n",
        "\n",
        "def compute_drift(global_model: nn.Module, client_param_lists: List[List[torch.Tensor]], device: torch.device) -> float:\n",
        "    with torch.no_grad():\n",
        "        gparams = [p.detach().to(device) for p in global_model.parameters()]\n",
        "        dists = []\n",
        "        for plist in client_param_lists:\n",
        "            s = 0.0\n",
        "            for gp, cp in zip(gparams, plist):\n",
        "                s += torch.norm(cp.to(device) - gp, p=2).item() ** 2\n",
        "            dists.append(math.sqrt(s))\n",
        "        return float(sum(dists) / len(dists))\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Data loading\n",
        "# ---------------------------\n",
        "\n",
        "def get_cifar10(root: str = \"./data\"):\n",
        "    tfm_train = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
        "    ])\n",
        "    tfm_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
        "    ])\n",
        "    train = datasets.CIFAR10(root, train=True, download=True, transform=tfm_train)\n",
        "    test = datasets.CIFAR10(root, train=False, download=True, transform=tfm_test)\n",
        "    return train, test\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fMlOPsnMUrKr"
      },
      "id": "fMlOPsnMUrKr",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #---------------------------\n",
        "# Training orchestration\n",
        "# ---------------------------\n",
        "\n",
        "def run(\n",
        "    strategy: str,\n",
        "    num_clients: int,\n",
        "    alpha: float,\n",
        "    rounds: int,\n",
        "    K: int,\n",
        "    batch_size: int,\n",
        "    lr: float,\n",
        "    momentum: float,\n",
        "    mu: float,\n",
        "    rho: float,\n",
        "    sample_frac: float,\n",
        "    seed: int = 42,\n",
        "    device_str: str = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "):\n",
        "    set_seed(seed)\n",
        "    device = torch.device(device_str)\n",
        "\n",
        "    # data\n",
        "    train_set, test_set = get_cifar10()\n",
        "    test_loader = DataLoader(test_set, batch_size=256, shuffle=False, num_workers=2)\n",
        "\n",
        "    # partition\n",
        "    targets = torch.tensor(train_set.targets)\n",
        "    splits = dirichlet_partition_indices(targets, num_clients=num_clients, alpha=alpha, seed=seed)\n",
        "\n",
        "    # model template\n",
        "    global_model = SmallCNN().to(device)\n",
        "    server = Server(global_model, device)\n",
        "\n",
        "    # client configs\n",
        "    cfg = ClientConfig(lr=lr, momentum=momentum, batch_size=batch_size, local_epochs=K, mu=mu, rho=rho)\n",
        "\n",
        "    # SCAFFOLD templates\n",
        "    scaffold_template = None\n",
        "    if strategy.lower() == \"scaffold\":\n",
        "        scaffold_template = [p.detach().clone() for p in global_model.parameters()]\n",
        "\n",
        "    # build clients\n",
        "    clients: List[Client] = []\n",
        "    for cid in range(num_clients):\n",
        "        clients.append(\n",
        "            Client(\n",
        "                cid=cid,\n",
        "                dataset=train_set,\n",
        "                indices=splits[cid],\n",
        "                device=device,\n",
        "                cfg=cfg,\n",
        "                strategy=strategy,\n",
        "                model_template=global_model,\n",
        "                scaffold_ci_template=scaffold_template,\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # SCAFFOLD global control variate c\n",
        "    c_global: Optional[List[torch.Tensor]] = None\n",
        "    if strategy.lower() == \"scaffold\":\n",
        "        c_global = [torch.zeros_like(p, device=device) for p in global_model.parameters()]\n",
        "\n",
        "    # training loop\n",
        "    frac = sample_frac\n",
        "    for rnd in range(1, rounds + 1):\n",
        "        # sample participating clients\n",
        "        m = max(1, int(round(frac * num_clients)))\n",
        "        selected = random.sample(range(num_clients), m)\n",
        "\n",
        "        # broadcast implicit via copying in local_train\n",
        "        results = []\n",
        "        for idx in selected:\n",
        "            res = clients[idx].local_train(global_model, c_global)\n",
        "            results.append((idx, res))\n",
        "\n",
        "        # weights by client data size\n",
        "        sizes = [int(res[\"num_samples\"]) for _, res in results]\n",
        "        total = sum(sizes)\n",
        "        weights = [s / total for s in sizes]\n",
        "\n",
        "        # metrics: drift before aggregation (based on current local params)\n",
        "        drift_val = compute_drift(global_model, [res[\"params\"] for _, res in results], device)\n",
        "\n",
        "        # aggregation\n",
        "        if strategy.lower() == \"fedgh\":\n",
        "            # harmonize flat deltas then add to global\n",
        "            flat = []\n",
        "            for _, res in results:\n",
        "                # concat layers (weighted delta will be applied after harmonization via weights)\n",
        "                deltas = res[\"delta\"]\n",
        "                flat.append(torch.cat([d.detach().view(-1).to(device) for d in deltas]))\n",
        "            flat_h = server.harmonize_pairwise(flat)\n",
        "            # reconstruct per-layer from flat\n",
        "            # We'll distribute harmonized flat deltas proportionally by weights\n",
        "            # First, split shapes\n",
        "            shapes = [p.shape for p in global_model.parameters()]\n",
        "            sizes_layer = [int(torch.tensor(s).prod()) for s in shapes]\n",
        "            per_client_deltas: List[List[torch.Tensor]] = []\n",
        "            for fh in flat_h:\n",
        "                offset = 0\n",
        "                dl = []\n",
        "                for sz, shp in zip(sizes_layer, shapes):\n",
        "                    dl.append(fh[offset:offset+sz].view(shp))\n",
        "                    offset += sz\n",
        "                per_client_deltas.append(dl)\n",
        "            server.aggregate_from_deltas(per_client_deltas, weights)\n",
        "        else:\n",
        "            # standard weighted average on parameters (FedAvg-style)\n",
        "            server.aggregate_weighted([res[\"params\"] for _, res in results], weights)\n",
        "\n",
        "        # SCAFFOLD: update c_global to average of ci\n",
        "        if strategy.lower() == \"scaffold\":\n",
        "            with torch.no_grad():\n",
        "                agg_ci = None\n",
        "                for _, res in results:\n",
        "                    ci_list = res[\"ci\"]  # type: ignore\n",
        "                    agg_ci = [t.clone() for t in ci_list] if agg_ci is None else [a + b for a, b in zip(agg_ci, ci_list)]\n",
        "                for i in range(len(agg_ci)):\n",
        "                    agg_ci[i] = agg_ci[i] / len(results)\n",
        "                for i, p in enumerate(c_global):\n",
        "                    p.copy_(agg_ci[i].to(device))\n",
        "\n",
        "        # eval\n",
        "        acc, loss = evaluate(global_model, test_loader, device)\n",
        "        print(f\"Round {rnd:03d} | clients {m:02d}/{num_clients} | drift {drift_val:.3f} | acc {acc*100:.2f}% | loss {loss:.4f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cgY5T2WXUyAt"
      },
      "id": "cgY5T2WXUyAt",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Setup: helpers, logging, and parser (run this once) ====\n",
        "import io, sys, os, re, time, json, shutil\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assumes a function run(**kwargs) is already defined in another cell.\n",
        "\n",
        "OUTDIR   = \"pa4_task4_runs\"   # root for artifacts\n",
        "ROUNDS   = 30                 # default rounds (consistent across methods)\n",
        "DOWNLOAD = True               # auto-download zips/plots (Colab)\n",
        "os.makedirs(OUTDIR, exist_ok=True)\n",
        "\n",
        "# Parse lines like: Round 001 | clients 10/10 | drift 3.103 | acc 33.10% | loss 2.1145\n",
        "line_re = re.compile(\n",
        "    r\"Round\\s+(\\d+)\\s+\\|\\s+clients\\s+(\\d+)\\/(\\d+)\\s+\\|\\s+drift\\s+([0-9.]+)\\s+\\|\\s+acc\\s+([0-9.]+)%\\s+\\|\\s+loss\\s+([0-9.]+)\"\n",
        ")\n",
        "\n",
        "def to_jsonable(x):\n",
        "    if isinstance(x, dict): return {str(k): to_jsonable(v) for k,v in x.items()}\n",
        "    if isinstance(x, (list, tuple)): return [to_jsonable(v) for v in x]\n",
        "    if isinstance(x, (str, int, float, bool)) or x is None: return x\n",
        "    try:\n",
        "        import numpy as np\n",
        "        if isinstance(x, np.generic): return x.item()\n",
        "    except: pass\n",
        "    try:\n",
        "        import torch\n",
        "        if isinstance(x, (torch.device, torch.dtype)): return str(x)\n",
        "    except: pass\n",
        "    return str(x)\n",
        "\n",
        "class Tee(io.TextIOBase):\n",
        "    \"\"\"Write to notebook + file simultaneously (live).\"\"\"\n",
        "    def __init__(self, file_obj, mirror): self.f, self.m = file_obj, mirror\n",
        "    def write(self, s): self.m.write(s); self.m.flush(); self.f.write(s); self.f.flush(); return len(s)\n",
        "    def flush(self): self.m.flush(); self.f.flush()\n",
        "\n",
        "def run_and_log(label: str, cfg: dict):\n",
        "    \"\"\"Runs one strategy once, prints live, saves logs/CSV/plots, and optionally zips+downloads.\"\"\"\n",
        "    stamp  = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    tag    = f\"{label}_alpha{cfg['alpha']}_K{cfg['K']}_N{cfg['num_clients']}_{stamp}\"\n",
        "    run_dir = os.path.join(OUTDIR, tag); os.makedirs(run_dir, exist_ok=True)\n",
        "\n",
        "    # Save config\n",
        "    cfg_to_save = dict(cfg); cfg_to_save[\"label\"] = label\n",
        "    with open(os.path.join(run_dir, \"config.json\"), \"w\") as f: json.dump(to_jsonable(cfg_to_save), f, indent=2)\n",
        "\n",
        "    # Live + file logging\n",
        "    log_path = os.path.join(run_dir, \"train.log\")\n",
        "    with open(log_path, \"w\") as logf:\n",
        "        old = sys.stdout; sys.stdout = Tee(logf, old)\n",
        "        try:\n",
        "            print(\"\\n\" + \"=\"*80); print(f\"Running {label}\"); print(\"=\"*80)\n",
        "            t0 = time.time()\n",
        "            run(**cfg)  # prints will appear live AND be written to train.log\n",
        "            print(f\"[{label}] elapsed: {time.time()-t0:.2f}s\")\n",
        "        finally:\n",
        "            sys.stdout = old\n",
        "\n",
        "    # Parse metrics from train.log\n",
        "    rows = []\n",
        "    with open(log_path) as f:\n",
        "        for line in f:\n",
        "            m = line_re.search(line)\n",
        "            if m:\n",
        "                rows.append((\n",
        "                    int(m.group(1)), int(m.group(2)), int(m.group(3)),\n",
        "                    float(m.group(4)), float(m.group(5))/100.0, float(m.group(6))\n",
        "                ))\n",
        "    df = pd.DataFrame(rows, columns=[\"round\",\"m_clients\",\"n_clients\",\"drift\",\"acc\",\"loss\"])\n",
        "    df.to_csv(os.path.join(run_dir, \"metrics.csv\"), index=False)\n",
        "\n",
        "    # Plots\n",
        "    if not df.empty:\n",
        "        for y, title, name in [\n",
        "            (\"acc\",  f\"{label} — Accuracy vs Rounds\", \"acc_vs_rounds.png\"),\n",
        "            (\"loss\", f\"{label} — Loss vs Rounds\",     \"loss_vs_rounds.png\"),\n",
        "            (\"drift\",f\"{label} — Drift vs Rounds\",    \"drift_vs_rounds.png\"),\n",
        "        ]:\n",
        "            plt.figure(); plt.plot(df[\"round\"], df[y]); plt.xlabel(\"Round\"); plt.ylabel(y.capitalize())\n",
        "            plt.title(title); plt.tight_layout()\n",
        "            plt.savefig(os.path.join(run_dir, name), dpi=150); plt.close()\n",
        "\n",
        "        best = df.loc[df[\"acc\"].idxmax()]\n",
        "        summary = dict(\n",
        "            final_round=int(df[\"round\"].iloc[-1]),\n",
        "            final_acc=float(df[\"acc\"].iloc[-1]),\n",
        "            best_acc=float(best[\"acc\"]),\n",
        "            best_round=int(best[\"round\"]),\n",
        "            final_loss=float(df[\"loss\"].iloc[-1]),\n",
        "            final_drift=float(df[\"drift\"].iloc[-1]),\n",
        "        )\n",
        "        with open(os.path.join(run_dir, \"summary.json\"), \"w\") as f: json.dump(summary, f, indent=2)\n",
        "        print(f\"[{label}] Final acc {summary['final_acc']:.3f} | Best {summary['best_acc']:.3f} @ r{summary['best_round']} | Drift {summary['final_drift']:.3f}\")\n",
        "    else:\n",
        "        print(f\"[{label}] WARN: no metrics parsed. Check train.log format.\")\n",
        "\n",
        "    # Zip + optional download\n",
        "    zip_path = shutil.make_archive(run_dir, \"zip\", run_dir)\n",
        "    if DOWNLOAD:\n",
        "        try:\n",
        "            from google.colab import files\n",
        "            files.download(zip_path)\n",
        "        except Exception as e:\n",
        "            print(f\"[{label}] Download skipped ({e}). Zip at: {zip_path}\")\n",
        "\n",
        "    return run_dir\n"
      ],
      "metadata": {
        "id": "PbE3HLKzkctn"
      },
      "id": "PbE3HLKzkctn",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_fedavg = dict(\n",
        "    strategy=\"fedavg\", num_clients=10, alpha=0.1, rounds=ROUNDS, K=5,\n",
        "    batch_size=64, lr=0.01, momentum=0.9, sample_frac=1.0, seed=42, mu=0.0, rho=0.0\n",
        ")\n",
        "run_dir_fedavg = run_and_log(\"FedAvg\", cfg_fedavg)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "id": "HT-t5lKZA5T6",
        "outputId": "b9e3b520-c8e7-450d-9b31-94891e721675"
      },
      "id": "HT-t5lKZA5T6",
      "execution_count": 8,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Running FedAvg\n",
            "================================================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170M/170M [00:04<00:00, 39.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 001 | clients 10/10 | drift 3.102 | acc 33.28% | loss 2.1141\n",
            "Round 002 | clients 10/10 | drift 3.011 | acc 41.39% | loss 1.7344\n",
            "Round 003 | clients 10/10 | drift 2.845 | acc 49.08% | loss 1.4711\n",
            "Round 004 | clients 10/10 | drift 2.727 | acc 54.18% | loss 1.3075\n",
            "Round 005 | clients 10/10 | drift 2.688 | acc 58.09% | loss 1.2105\n",
            "Round 006 | clients 10/10 | drift 2.699 | acc 61.17% | loss 1.1045\n",
            "Round 007 | clients 10/10 | drift 2.673 | acc 63.22% | loss 1.0543\n",
            "Round 008 | clients 10/10 | drift 2.683 | acc 63.94% | loss 1.0244\n",
            "Round 009 | clients 10/10 | drift 2.690 | acc 66.43% | loss 0.9715\n",
            "Round 010 | clients 10/10 | drift 2.720 | acc 67.80% | loss 0.9347\n",
            "Round 011 | clients 10/10 | drift 2.751 | acc 68.05% | loss 0.9231\n",
            "Round 012 | clients 10/10 | drift 2.771 | acc 69.02% | loss 0.8916\n",
            "Round 013 | clients 10/10 | drift 2.832 | acc 69.10% | loss 0.9054\n",
            "Round 014 | clients 10/10 | drift 2.804 | acc 70.24% | loss 0.8656\n",
            "Round 015 | clients 10/10 | drift 2.844 | acc 70.40% | loss 0.8669\n",
            "Round 016 | clients 10/10 | drift 2.844 | acc 70.90% | loss 0.8423\n",
            "Round 017 | clients 10/10 | drift 2.953 | acc 70.98% | loss 0.8397\n",
            "Round 018 | clients 10/10 | drift 2.917 | acc 71.38% | loss 0.8251\n",
            "Round 019 | clients 10/10 | drift 2.955 | acc 71.95% | loss 0.8238\n",
            "Round 020 | clients 10/10 | drift 2.998 | acc 71.62% | loss 0.8235\n",
            "Round 021 | clients 10/10 | drift 2.998 | acc 72.20% | loss 0.8113\n",
            "Round 022 | clients 10/10 | drift 3.047 | acc 72.04% | loss 0.8157\n",
            "Round 023 | clients 10/10 | drift 3.057 | acc 72.42% | loss 0.8102\n",
            "Round 024 | clients 10/10 | drift 3.072 | acc 71.85% | loss 0.8362\n",
            "Round 025 | clients 10/10 | drift 3.094 | acc 72.50% | loss 0.8184\n",
            "Round 026 | clients 10/10 | drift 3.153 | acc 73.05% | loss 0.8056\n",
            "Round 027 | clients 10/10 | drift 3.104 | acc 72.69% | loss 0.8204\n",
            "Round 028 | clients 10/10 | drift 3.169 | acc 72.82% | loss 0.8130\n",
            "Round 029 | clients 10/10 | drift 3.209 | acc 73.11% | loss 0.8170\n",
            "Round 030 | clients 10/10 | drift 3.203 | acc 73.26% | loss 0.8062\n",
            "[FedAvg] elapsed: 2759.46s\n",
            "[FedAvg] Final acc 0.733 | Best 0.733 @ r30 | Drift 3.203\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f030e813-38fd-4d36-99b7-56ec4ddd6392\", \"FedAvg_alpha0.1_K5_N10_20251110-131931.zip\", 106521)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_fedprox = dict(\n",
        "    strategy=\"fedprox\", num_clients=10, alpha=0.1, rounds=ROUNDS, K=5,\n",
        "    batch_size=64, lr=0.01, momentum=0.9, sample_frac=1.0, seed=42, mu=0.01, rho=0.0\n",
        ")\n",
        "run_dir_fedprox = run_and_log(\"FedProx\", cfg_fedprox)\n"
      ],
      "metadata": {
        "id": "etP2jqG5Q3nx",
        "outputId": "7a9008c1-2cf1-4b09-efb1-18eeb33494e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        }
      },
      "id": "etP2jqG5Q3nx",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "Running FedProx\n",
            "================================================================================\n",
            "Round 001 | clients 10/10 | drift 2.646 | acc 36.54% | loss 2.1058\n",
            "Round 002 | clients 10/10 | drift 2.557 | acc 40.36% | loss 1.7754\n",
            "Round 003 | clients 10/10 | drift 2.403 | acc 47.97% | loss 1.5187\n",
            "Round 004 | clients 10/10 | drift 2.282 | acc 52.74% | loss 1.3620\n",
            "Round 005 | clients 10/10 | drift 2.239 | acc 56.20% | loss 1.2667\n",
            "Round 006 | clients 10/10 | drift 2.234 | acc 58.99% | loss 1.1704\n",
            "Round 007 | clients 10/10 | drift 2.212 | acc 61.29% | loss 1.1128\n",
            "Round 008 | clients 10/10 | drift 2.207 | acc 61.46% | loss 1.0938\n",
            "Round 009 | clients 10/10 | drift 2.206 | acc 64.04% | loss 1.0246\n",
            "Round 010 | clients 10/10 | drift 2.233 | acc 65.20% | loss 0.9969\n",
            "Round 011 | clients 10/10 | drift 2.247 | acc 66.69% | loss 0.9459\n",
            "Round 012 | clients 10/10 | drift 2.261 | acc 67.28% | loss 0.9299\n",
            "Round 013 | clients 10/10 | drift 2.304 | acc 68.13% | loss 0.9209\n",
            "Round 014 | clients 10/10 | drift 2.282 | acc 69.29% | loss 0.8891\n",
            "Round 015 | clients 10/10 | drift 2.298 | acc 69.52% | loss 0.8799\n",
            "Round 016 | clients 10/10 | drift 2.287 | acc 70.04% | loss 0.8556\n",
            "Round 017 | clients 10/10 | drift 2.368 | acc 70.58% | loss 0.8532\n",
            "Round 018 | clients 10/10 | drift 2.346 | acc 70.97% | loss 0.8344\n",
            "Round 019 | clients 10/10 | drift 2.396 | acc 71.75% | loss 0.8275\n",
            "Round 020 | clients 10/10 | drift 2.410 | acc 71.61% | loss 0.8193\n",
            "Round 021 | clients 10/10 | drift 2.411 | acc 71.48% | loss 0.8211\n",
            "Round 022 | clients 10/10 | drift 2.446 | acc 72.16% | loss 0.8074\n",
            "Round 023 | clients 10/10 | drift 2.451 | acc 72.52% | loss 0.7948\n",
            "Round 024 | clients 10/10 | drift 2.469 | acc 72.31% | loss 0.8015\n",
            "Round 025 | clients 10/10 | drift 2.481 | acc 72.37% | loss 0.8031\n",
            "Round 026 | clients 10/10 | drift 2.528 | acc 72.91% | loss 0.7887\n",
            "Round 027 | clients 10/10 | drift 2.511 | acc 73.18% | loss 0.7927\n",
            "Round 028 | clients 10/10 | drift 2.538 | acc 73.00% | loss 0.7963\n",
            "Round 029 | clients 10/10 | drift 2.561 | acc 73.33% | loss 0.7867\n",
            "Round 030 | clients 10/10 | drift 2.575 | acc 73.66% | loss 0.7746\n",
            "[FedProx] elapsed: 2944.19s\n",
            "[FedProx] Final acc 0.737 | Best 0.737 @ r30 | Drift 2.575\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_105a990d-2363-4360-8874-dc7850bfbffd\", \"FedProx_alpha0.1_K5_N10_20251110-140531.zip\", 105481)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_scaffold = dict(\n",
        "    strategy=\"scaffold\",\n",
        "    num_clients=10, alpha=0.1, rounds=ROUNDS, K=3,\n",
        "    batch_size=64, lr=0.005, momentum=0.0, sample_frac=1.0,\n",
        "    seed=42, mu=0.0, rho=0.0\n",
        ")\n",
        "run_dir_scaffold = run_and_log(\"SCAFFOLD\", cfg_scaffold)\n"
      ],
      "metadata": {
        "id": "VutWgizf644d",
        "outputId": "99ee122c-148d-4f3f-b2f9-6e4d598860aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        }
      },
      "id": "VutWgizf644d",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "Running SCAFFOLD\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "cannot access local variable 'loss' where it is not associated with a value",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1899040811.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mrun_dir_scaffold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_and_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SCAFFOLD\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg_scaffold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2680451035.py\u001b[0m in \u001b[0;36mrun_and_log\u001b[0;34m(label, cfg)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Running {label}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# prints will appear live AND be written to train.log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[{label}] elapsed: {time.time()-t0:.2f}s\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1102460269.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(strategy, num_clients, alpha, rounds, K, batch_size, lr, momentum, mu, rho, sample_frac, seed, device_str)\u001b[0m\n\u001b[1;32m     72\u001b[0m        \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselected\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m            \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_global\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m            \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-934513191.py\u001b[0m in \u001b[0;36mlocal_train\u001b[0;34m(self, global_model, c_global)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m                   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[Client {self.cid}] non-finite loss; breaking batch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                   \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'loss' where it is not associated with a value"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# combined accuracy plot\n",
        "if all_curves:\n",
        "    comb = pd.concat(all_curves, ignore_index=True)\n",
        "    plt.figure()\n",
        "    for label, grp in comb.groupby(\"label\"):\n",
        "        plt.plot(grp[\"round\"], grp[\"acc\"], label=label)\n",
        "    plt.xlabel(\"Round\"); plt.ylabel(\"Accuracy\")\n",
        "    plt.title(f\"Accuracy vs Rounds — All Strategies ({common_cfg['rounds']} rounds)\")\n",
        "    plt.legend(); plt.tight_layout()\n",
        "    combo_path = os.path.join(OUTDIR, f\"combined_accuracy_{common_cfg['rounds']}r.png\")\n",
        "    plt.savefig(combo_path, dpi=160); plt.close()\n",
        "    print(f\"Combined accuracy plot saved -> {combo_path}\")\n",
        "\n",
        "print(f\"All artifacts under: {os.path.abspath(OUTDIR)}\")"
      ],
      "metadata": {
        "id": "MXtiPYhkA4UJ"
      },
      "id": "MXtiPYhkA4UJ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}