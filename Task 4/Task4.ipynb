{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"\n",
        "ATML PA4 — Task 4 from scratch (no reuse):\n",
        "A clean, single-file PyTorch implementation of a small federated learning framework\n",
        "with four heterogeneity-mitigation strategies:\n",
        "- FedProx (local proximal regularization)\n",
        "- SCAFFOLD (control variates)\n",
        "- FedGH (server-side gradient harmonization)\n",
        "- FedSAM (sharpness-aware minimization on clients)\n",
        "\n",
        "\n",
        "Also includes:\n",
        "- CIFAR-10 loading and Dirichlet non-IID partitioning\n",
        "- Simple CNN model\n",
        "- FedAvg baseline\n",
        "- Weighted aggregation, client drift metric, logging hooks\n",
        "\n",
        "\n",
        "HOW TO USE (example):\n",
        "python ATML-PA4-Task4.py --strategy fedavg --alpha 0.1 --num-clients 10 --rounds 50 --K 5\n",
        "python ATML-PA4-Task4.py --strategy fedprox --mu 0.01 --alpha 0.1 --num-clients 10 --rounds 50 --K 5\n",
        "python ATML-PA4-Task4.py --strategy scaffold --alpha 0.1 --num-clients 10 --rounds 50 --K 5\n",
        "python ATML-PA4-Task4.py --strategy fedgh --alpha 0.1 --num-clients 10 --rounds 50 --K 5\n",
        "python ATML-PA4-Task4.py --strategy fedsam --rho 0.05 --alpha 0.1 --num-clients 10 --rounds 50 --K 5\n",
        "\n",
        "\n",
        "Notes:\n",
        "* Keep the model small to fit within assignment constraints.\n",
        "* SCAFFOLD doubles comms (sends control variates). FedSAM ~2x local compute.\n",
        "* FedGH adds O(M^2) server-time pairwise projections per round.\n",
        "\n",
        "\n",
        "This file is deliberately verbose and self-contained for clarity and grading.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Rd1DZxVkv98w"
      },
      "id": "Rd1DZxVkv98w"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "6634b3d6",
      "metadata": {
        "id": "6634b3d6"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "import argparse\n",
        "import copy\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Tuple, Iterable, Optional\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "# torchvision is permissible for CIFAR-10\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Reproducibility helpers\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "  random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  os.environ[\"PYTHONHASHSEED\"] = str(seed)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# Simple CNN for CIFAR-10\n",
        "# ---------------------------\n",
        "class SmallCNN(nn.Module):\n",
        "    def __init__(self, num_classes: int = 10):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),  # 16x16\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),  # 8x8\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 8 * 8, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(256, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Dirichlet non-IID partition\n",
        "# ---------------------------\n",
        "\n",
        "def dirichlet_partition_indices(\n",
        "    targets: torch.Tensor, num_clients: int, alpha: float, seed: int = 42\n",
        ") -> List[List[int]]:\n",
        "    \"\"\"Split dataset indices into num_clients using class-wise Dirichlet(α) proportions.\n",
        "    Smaller α => higher label skew.\n",
        "    \"\"\"\n",
        "    g = torch.Generator().manual_seed(seed)\n",
        "    num_classes = int(targets.max().item() + 1)\n",
        "    class_indices = [torch.where(targets == c)[0].tolist() for c in range(num_classes)]\n",
        "    for ci in class_indices:\n",
        "        random.shuffle(ci)\n",
        "\n",
        "    client_indices = [[] for _ in range(num_clients)]\n",
        "\n",
        "    for c in range(num_classes):\n",
        "        # sample proportions for this class\n",
        "        proportions = torch.distributions.Dirichlet(torch.full((num_clients,), alpha)).sample()\n",
        "        proportions = (proportions / proportions.sum()).tolist()\n",
        "        cls_ids = class_indices[c]\n",
        "        # split cls_ids according to proportions\n",
        "        prev = 0\n",
        "        for k in range(num_clients):\n",
        "            take = int(round(proportions[k] * len(cls_ids)))\n",
        "            client_indices[k].extend(cls_ids[prev : prev + take])\n",
        "            prev += take\n",
        "        # in case of rounding leftovers, dump remainder into last client\n",
        "        if prev < len(cls_ids):\n",
        "            client_indices[-1].extend(cls_ids[prev:])\n",
        "\n",
        "    # shuffle each client list\n",
        "    for k in range(num_clients):\n",
        "        random.shuffle(client_indices[k])\n",
        "    return client_indices\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Utilities for (de)flattening params and deltas\n",
        "# ---------------------------\n",
        "\n",
        "def get_model_params_vector(model: nn.Module) -> torch.Tensor:\n",
        "    return torch.cat([p.detach().view(-1) for p in model.parameters()])\n",
        "\n",
        "\n",
        "def get_model_grads_vector(model: nn.Module) -> torch.Tensor:\n",
        "    return torch.cat([p.grad.detach().view(-1) if p.grad is not None else torch.zeros_like(p).view(-1) for p in model.parameters()])\n",
        "\n",
        "\n",
        "def assign_params_from_vector(model: nn.Module, vec: torch.Tensor):\n",
        "    offset = 0\n",
        "    with torch.no_grad():\n",
        "        for p in model.parameters():\n",
        "            numel = p.numel()\n",
        "            p.copy_(vec[offset : offset + numel].view_as(p))\n",
        "            offset += numel\n",
        "\n",
        "\n",
        "def add_inplace(tensors: Iterable[torch.Tensor], alphas: Iterable[float], out: torch.Tensor):\n",
        "    \"\"\"out = sum(alpha_i * tensor_i). Assumes flat vectors of equal shape.\"\"\"\n",
        "    out.zero_()\n",
        "    for t, a in zip(tensors, alphas):\n",
        "        out.add_(t, alpha=a)"
      ],
      "metadata": {
        "id": "Fax6TzrSUcou"
      },
      "id": "Fax6TzrSUcou",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# Client logic (baseline + hooks)\n",
        "# ---------------------------\n",
        "@dataclass\n",
        "class ClientConfig:\n",
        "    lr: float = 0.01\n",
        "    momentum: float = 0.9\n",
        "    batch_size: int = 64\n",
        "    local_epochs: int = 5  # K\n",
        "    mu: float = 0.0  # for FedProx\n",
        "    rho: float = 0.0  # for FedSAM\n",
        "\n",
        "\n",
        "def freeze_bn_running_stats(model: nn.Module):\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, torch.nn.modules.batchnorm._BatchNorm):\n",
        "            m.eval()                      # stop updating running_mean/var\n",
        "            m.track_running_stats = False # disable counters entirely\n",
        "\n",
        "\n",
        "class Client:\n",
        "    def __init__(\n",
        "        self,\n",
        "        cid: int,\n",
        "        dataset: torch.utils.data.Dataset,\n",
        "        indices: List[int],\n",
        "        device: torch.device,\n",
        "        cfg: ClientConfig,\n",
        "        strategy: str,\n",
        "        model_template: nn.Module,\n",
        "        scaffold_ci_template: Optional[List[torch.Tensor]] = None,\n",
        "    ):\n",
        "        self.cid = cid\n",
        "        self.device = device\n",
        "        self.cfg = cfg\n",
        "        self.strategy = strategy.lower()\n",
        "        self.loader = DataLoader(Subset(dataset, indices), batch_size=cfg.batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "        self.model = copy.deepcopy(model_template).to(device)\n",
        "\n",
        "        # SCAFFOLD control variate for this client (list of tensors matching params)\n",
        "        if self.strategy == \"scaffold\":\n",
        "            assert scaffold_ci_template is not None\n",
        "            self.ci = [torch.zeros_like(t, device=device) for t in scaffold_ci_template]\n",
        "        else:\n",
        "            self.ci = None\n",
        "\n",
        "    def set_model_from_global(self, global_model: nn.Module):\n",
        "        self.model.load_state_dict(copy.deepcopy(global_model.state_dict()))\n",
        "\n",
        "    def _scaffold_apply_correction(self, model: nn.Module, c_global: List[torch.Tensor]):\n",
        "        # add (c - ci) to each parameter's gradient  [SCAFFOLD paper]\n",
        "        with torch.no_grad():\n",
        "            for p, ci_p, c_p in zip(model.parameters(), self.ci, c_global):\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                p.grad.add_(c_p - ci_p)\n",
        "\n",
        "\n",
        "    def _fedprox_add_proximal(self, model: nn.Module, global_params: List[torch.Tensor]):\n",
        "        # add µ/2 * ||theta - theta_g||^2 to loss => grads add µ*(theta - theta_g)\n",
        "        mu = self.cfg.mu\n",
        "        if mu <= 0:\n",
        "            return 0.0\n",
        "        prox = 0.0\n",
        "        for p, g in zip(model.parameters(), global_params):\n",
        "            prox = prox + 0.5 * mu * torch.sum((p - g) ** 2)\n",
        "        return prox\n",
        "\n",
        "    def _fedsam_ascent(self, model: nn.Module, rho: float):\n",
        "        # Perturb weights: w_adv = w + rho * g/||g|| (g is grad w.r.t current w)\n",
        "        grad_vec = get_model_grads_vector(model)\n",
        "        eps = 1e-12\n",
        "        scale = rho / (grad_vec.norm(p=2) + eps)\n",
        "        offset = 0\n",
        "        with torch.no_grad():\n",
        "            for p in model.parameters():\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                numel = p.numel()\n",
        "                p.add_(grad_vec[offset : offset + numel].view_as(p), alpha=scale)\n",
        "                offset += numel\n",
        "\n",
        "    def _fedsam_descent_restore(self, model: nn.Module, rho: float):\n",
        "        # Undo the perturbation by subtracting same delta applied in ascent.\n",
        "        # NOTE: We recompute using the *current* grad vector, which is at w_adv; to precisely undo, we stored nothing.\n",
        "        # A more exact impl would store the ascent delta. We'll compute it again from grads-at-w (before ascent),\n",
        "        # but we no longer have those grads. So we do the simple approach: store ascent deltas.\n",
        "        pass  # We'll store deltas explicitly below.\n",
        "\n",
        "    def local_train(\n",
        "        self,\n",
        "        global_model: nn.Module,\n",
        "        c_global: Optional[List[torch.Tensor]] = None,\n",
        "    ) -> Dict[str, torch.Tensor | List[torch.Tensor]]:\n",
        "        device = self.device\n",
        "        self.set_model_from_global(global_model)\n",
        "        model = self.model\n",
        "        model.train()\n",
        "        if self.strategy == \"scaffold\":\n",
        "            freeze_bn_running_stats(model)\n",
        "\n",
        "        # momentum OFF for SCAFFOLD; else use cfg\n",
        "        use_momentum = 0.0 if self.strategy == \"scaffold\" else self.cfg.momentum\n",
        "        wd = 5e-4 if self.strategy == \"scaffold\" else 0.0\n",
        "        opt = optim.SGD(model.parameters(), lr=self.cfg.lr, momentum=use_momentum, weight_decay=wd)\n",
        "\n",
        "\n",
        "        # cache global params for FedProx term\n",
        "        global_params = [p.detach().clone() for p in global_model.parameters()]\n",
        "        rho = self.cfg.rho if self.strategy == \"fedsam\" else 0.0\n",
        "\n",
        "        total_steps = 0  # count mini-batch steps (needed for SCAFFOLD)\n",
        "\n",
        "        for ep in range(self.cfg.local_epochs):\n",
        "            for xb, yb in self.loader:\n",
        "                xb, yb = xb.to(device, non_blocking=True), yb.to(device, non_blocking=True)\n",
        "\n",
        "                # ----- forward -----\n",
        "                opt.zero_grad(set_to_none=True)\n",
        "                logits = model(xb)\n",
        "                loss = F.cross_entropy(logits, yb)\n",
        "\n",
        "                # FedProx proximal term\n",
        "                if self.strategy == \"fedprox\" and self.cfg.mu > 0:\n",
        "                    loss = loss + self._fedprox_add_proximal(model, global_params)\n",
        "\n",
        "                # guard BEFORE backward\n",
        "                if not torch.isfinite(loss):\n",
        "                    print(f\"[Client {self.cid}] non-finite loss; breaking batch\")\n",
        "                    break\n",
        "\n",
        "                # ----- backward -----\n",
        "                loss.backward()\n",
        "\n",
        "                # SCAFFOLD correction: g <- g + (ci - c)\n",
        "                if self.strategy == \"scaffold\":\n",
        "                    assert c_global is not None and self.ci is not None\n",
        "                    self._scaffold_apply_correction(model, c_global)\n",
        "\n",
        "                # grad guard + light clip\n",
        "                bad_grad = False\n",
        "                for p in model.parameters():\n",
        "                    if p.grad is None:\n",
        "                        continue\n",
        "                    g = p.grad\n",
        "                    mask = torch.isfinite(g)\n",
        "                    if not mask.all():\n",
        "                        g[~mask] = 0.0\n",
        "                        bad_grad = True\n",
        "                if bad_grad:\n",
        "                    # if something blew up, take a tiny step or skip\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                else:\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)\n",
        "\n",
        "\n",
        "\n",
        "                # FedSAM two-step or vanilla step\n",
        "                if self.strategy == \"fedsam\" and rho > 0:\n",
        "                    ascent_deltas = []\n",
        "                    with torch.no_grad():\n",
        "                        grad_vec = get_model_grads_vector(model)\n",
        "                        eps = 1e-12\n",
        "                        scale = rho / (grad_vec.norm(p=2) + eps)\n",
        "                        off = 0\n",
        "                        for p in model.parameters():\n",
        "                            if p.grad is None:\n",
        "                                ascent_deltas.append(None); continue\n",
        "                            n = p.numel()\n",
        "                            delta = grad_vec[off:off+n].view_as(p) * scale\n",
        "                            p.add_(delta); ascent_deltas.append(delta); off += n\n",
        "\n",
        "                    opt.zero_grad(set_to_none=True)\n",
        "                    logits_adv = model(xb)\n",
        "                    loss_adv = F.cross_entropy(logits_adv, yb)\n",
        "                    loss_adv.backward()\n",
        "\n",
        "                    with torch.no_grad():\n",
        "                        for p, d in zip(model.parameters(), ascent_deltas):\n",
        "                            if d is not None: p.sub_(d)\n",
        "\n",
        "                    opt.step()\n",
        "                else:\n",
        "                    opt.step()\n",
        "\n",
        "                total_steps += 1\n",
        "\n",
        "        # ----- package results -----\n",
        "        with torch.no_grad():\n",
        "            theta_i = [p.detach().clone() for p in model.parameters()]\n",
        "            theta_g = [p.detach().clone() for p in global_model.parameters()]\n",
        "            deltas  = [ti - tg for ti, tg in zip(theta_i, theta_g)]\n",
        "\n",
        "        out: Dict[str, torch.Tensor | List[torch.Tensor]] = {\n",
        "            \"params\": theta_i,\n",
        "            \"delta\": deltas,\n",
        "            \"num_samples\": int(len(self.loader.dataset)),\n",
        "        }\n",
        "\n",
        "        # SCAFFOLD: ci <- ci - c + (w_t - w_{t+1}^i) / (steps * lr)\n",
        "        if self.strategy == \"scaffold\":\n",
        "            assert self.ci is not None and c_global is not None\n",
        "            steps = max(total_steps, 1)\n",
        "            inv = 1.0 / (steps * self.cfg.lr)\n",
        "            with torch.no_grad():\n",
        "                for ci_p, c_p, wt_p, wt1i_p in zip(self.ci, c_global, theta_g, theta_i):\n",
        "                    ci_p.add_(-c_p)\n",
        "                    ci_p.add_((wt_p - wt1i_p) * inv)\n",
        "            out[\"ci\"] = [t.detach().clone() for t in self.ci]\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3MzlH8atUn3-"
      },
      "id": "3MzlH8atUn3-",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# Server & strategies\n",
        "# ---------------------------\n",
        "class Server:\n",
        "    def __init__(self, model: nn.Module, device: torch.device):\n",
        "        self.model = model.to(device)\n",
        "        self.device = device\n",
        "\n",
        "    def aggregate_weighted(self, client_params: List[List[torch.Tensor]], weights: List[float]):\n",
        "        with torch.no_grad():\n",
        "            for p_idx, p in enumerate(self.model.parameters()):\n",
        "                acc = None\n",
        "                for w, params in zip(weights, client_params):\n",
        "                    term = params[p_idx].to(self.device) * w\n",
        "                    acc = term if acc is None else acc + term\n",
        "                p.copy_(acc)\n",
        "\n",
        "    def aggregate_from_deltas(self, deltas: List[List[torch.Tensor]], weights: List[float]):\n",
        "        with torch.no_grad():\n",
        "            for p_idx, p in enumerate(self.model.parameters()):\n",
        "                acc = torch.zeros_like(p)\n",
        "                for w, dlist in zip(weights, deltas):\n",
        "                    acc.add_(dlist[p_idx].to(self.device), alpha=w)\n",
        "                p.add_(acc)\n",
        "\n",
        "    # FedGH: harmonize deltas before averaging\n",
        "    def harmonize_pairwise(self, flat_updates: List[torch.Tensor]) -> List[torch.Tensor]:\n",
        "        M = len(flat_updates)\n",
        "        outs = [u.clone() for u in flat_updates]\n",
        "        for i in range(M):\n",
        "            for j in range(i + 1, M):\n",
        "                gi, gj = outs[i], outs[j]\n",
        "                dot = torch.dot(gi, gj)\n",
        "                if dot < 0:\n",
        "                    # project symmetric\n",
        "                    gi_norm2 = torch.dot(gi, gi) + 1e-12\n",
        "                    gj_norm2 = torch.dot(gj, gj) + 1e-12\n",
        "                    proj_i = dot / gj_norm2\n",
        "                    proj_j = dot / gi_norm2\n",
        "                    outs[i] = gi - proj_i * gj\n",
        "                    outs[j] = gj - proj_j * gi\n",
        "        return outs\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Evaluation & metrics\n",
        "# ---------------------------\n",
        "@torch.no_grad()\n",
        "def evaluate(model: nn.Module, loader: DataLoader, device: torch.device) -> Tuple[float, float]:\n",
        "    model.eval()\n",
        "    total, correct, loss_sum = 0, 0, 0.0\n",
        "    for xb, yb in loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        logits = model(xb)\n",
        "        loss = F.cross_entropy(logits, yb, reduction='sum')\n",
        "        preds = logits.argmax(dim=1)\n",
        "        correct += (preds == yb).sum().item()\n",
        "        total += yb.size(0)\n",
        "        loss_sum += loss.item()\n",
        "    return correct / total, loss_sum / total\n",
        "\n",
        "\n",
        "def compute_drift(global_model: nn.Module, client_param_lists: List[List[torch.Tensor]], device: torch.device) -> float:\n",
        "    with torch.no_grad():\n",
        "        gparams = [p.detach().to(device) for p in global_model.parameters()]\n",
        "        dists = []\n",
        "        for plist in client_param_lists:\n",
        "            s = 0.0\n",
        "            for gp, cp in zip(gparams, plist):\n",
        "                s += torch.norm(cp.to(device) - gp, p=2).item() ** 2\n",
        "            dists.append(math.sqrt(s))\n",
        "        return float(sum(dists) / len(dists))\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Data loading\n",
        "# ---------------------------\n",
        "\n",
        "def get_cifar10(root: str = \"./data\"):\n",
        "    tfm_train = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
        "    ])\n",
        "    tfm_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
        "    ])\n",
        "    train = datasets.CIFAR10(root, train=True, download=True, transform=tfm_train)\n",
        "    test = datasets.CIFAR10(root, train=False, download=True, transform=tfm_test)\n",
        "    return train, test\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fMlOPsnMUrKr"
      },
      "id": "fMlOPsnMUrKr",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #---------------------------\n",
        "# Training orchestration\n",
        "# ---------------------------\n",
        "\n",
        "def run(\n",
        "    strategy: str,\n",
        "    num_clients: int,\n",
        "    alpha: float,\n",
        "    rounds: int,\n",
        "    K: int,\n",
        "    batch_size: int,\n",
        "    lr: float,\n",
        "    momentum: float,\n",
        "    mu: float,\n",
        "    rho: float,\n",
        "    sample_frac: float,\n",
        "    seed: int = 42,\n",
        "    device_str: str = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "):\n",
        "    set_seed(seed)\n",
        "    device = torch.device(device_str)\n",
        "\n",
        "    # data\n",
        "    train_set, test_set = get_cifar10()\n",
        "    test_loader = DataLoader(test_set, batch_size=256, shuffle=False, num_workers=2)\n",
        "\n",
        "    # partition\n",
        "    targets = torch.tensor(train_set.targets)\n",
        "    splits = dirichlet_partition_indices(targets, num_clients=num_clients, alpha=alpha, seed=seed)\n",
        "\n",
        "    # model template\n",
        "    global_model = SmallCNN().to(device)\n",
        "    server = Server(global_model, device)\n",
        "\n",
        "    # client configs\n",
        "    cfg = ClientConfig(lr=lr, momentum=momentum, batch_size=batch_size, local_epochs=K, mu=mu, rho=rho)\n",
        "\n",
        "    # SCAFFOLD templates\n",
        "    scaffold_template = None\n",
        "    if strategy.lower() == \"scaffold\":\n",
        "        scaffold_template = [p.detach().clone() for p in global_model.parameters()]\n",
        "\n",
        "    # build clients\n",
        "    clients: List[Client] = []\n",
        "    for cid in range(num_clients):\n",
        "        clients.append(\n",
        "            Client(\n",
        "                cid=cid,\n",
        "                dataset=train_set,\n",
        "                indices=splits[cid],\n",
        "                device=device,\n",
        "                cfg=cfg,\n",
        "                strategy=strategy,\n",
        "                model_template=global_model,\n",
        "                scaffold_ci_template=scaffold_template,\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # SCAFFOLD global control variate c\n",
        "    c_global: Optional[List[torch.Tensor]] = None\n",
        "    if strategy.lower() == \"scaffold\":\n",
        "        c_global = [torch.zeros_like(p, device=device) for p in global_model.parameters()]\n",
        "\n",
        "\n",
        "    # training loop\n",
        "    frac = sample_frac\n",
        "    for rnd in range(1, rounds + 1):\n",
        "        # --- round LR schedule ---\n",
        "        base_lr = lr\n",
        "        min_lr  = 0.003  # floor to avoid vanishing updates\n",
        "        if rnd <= 2:\n",
        "            lr_r = base_lr * 0.5 * rnd  # warmup: 0.5x, 1.0x\n",
        "        else:\n",
        "            import math\n",
        "            cos = 0.5 * (1.0 + math.cos(math.pi * (rnd - 2) / max(1, (rounds - 2))))\n",
        "            lr_r = min_lr + (base_lr - min_lr) * cos\n",
        "\n",
        "        # sample participating clients\n",
        "        m = max(1, int(round(frac * num_clients)))\n",
        "        selected = random.sample(range(num_clients), m)\n",
        "\n",
        "        for idx in selected:\n",
        "          clients[idx].cfg.lr = lr_r\n",
        "\n",
        "\n",
        "        # collect results (+ snapshot ci for SCAFFOLD)\n",
        "        results = []\n",
        "        old_ci = {}\n",
        "        for idx in selected:\n",
        "            if strategy.lower() == \"scaffold\":\n",
        "                old_ci[idx] = [t.clone() for t in clients[idx].ci]\n",
        "            res = clients[idx].local_train(global_model, c_global)\n",
        "            results.append((idx, res))\n",
        "\n",
        "        # FILTER bad results\n",
        "        clean = []\n",
        "        for cid, res in results:\n",
        "            if res is None:\n",
        "                print(f\"[Server] skip client {cid}: returned None\"); continue\n",
        "            ns = res.get(\"num_samples\", 0)\n",
        "            try:\n",
        "                ns = int(ns)\n",
        "            except Exception:\n",
        "                print(f\"[Server] skip client {cid}: bad num_samples={res.get('num_samples')}\"); continue\n",
        "            if ns <= 0:\n",
        "                print(f\"[Server] skip client {cid}: num_samples<=0\"); continue\n",
        "            bad = False\n",
        "            for p in res.get(\"params\", []):\n",
        "                if not torch.isfinite(p).all():\n",
        "                    bad = True; break\n",
        "            if bad:\n",
        "                print(f\"[Server] skip client {cid}: non-finite params\"); continue\n",
        "            clean.append((cid, res))\n",
        "\n",
        "        if not clean:\n",
        "            print(f\"[Server] Round {rnd:03d}: no valid client results, skipping aggregation\")\n",
        "            acc, loss = evaluate(global_model, test_loader, device)\n",
        "            print(f\"Round {rnd:03d} | clients 00/{num_clients} | drift nan | acc {acc*100:.2f}% | loss {loss:.4f}\")\n",
        "            continue\n",
        "\n",
        "        # weights\n",
        "        sizes = [int(res[\"num_samples\"]) for _, res in clean]\n",
        "        total = sum(sizes)\n",
        "        weights = [s / total for s in sizes]\n",
        "\n",
        "        # drift before aggregation\n",
        "        drift_val = compute_drift(global_model, [res[\"params\"] for _, res in clean], device)\n",
        "\n",
        "        # aggregate\n",
        "        if strategy.lower() == \"fedgh\":\n",
        "            flat = []\n",
        "            for _, res in clean:\n",
        "                deltas = res[\"delta\"]\n",
        "                flat.append(torch.cat([d.detach().view(-1).to(device) for d in deltas]))\n",
        "            flat_h = server.harmonize_pairwise(flat)\n",
        "            shapes = [p.shape for p in global_model.parameters()]\n",
        "            sizes_layer = [int(torch.tensor(s).prod()) for s in shapes]\n",
        "            per_client_deltas = []\n",
        "            for fh in flat_h:\n",
        "                off = 0; dl = []\n",
        "                for sz, shp in zip(sizes_layer, shapes):\n",
        "                    dl.append(fh[off:off+sz].view(shp)); off += sz\n",
        "                per_client_deltas.append(dl)\n",
        "            server.aggregate_from_deltas(per_client_deltas, weights)\n",
        "        else:\n",
        "            server.aggregate_weighted([res[\"params\"] for _, res in clean], weights)\n",
        "\n",
        "        # SCAFFOLD: c_global += mean(Δci)  (incremental update)\n",
        "        # --- SCAFFOLD: c_global += weighted mean(Δci) ---\n",
        "        if strategy.lower() == \"scaffold\":\n",
        "            with torch.no_grad():\n",
        "                sum_delta = [torch.zeros_like(p, device=device) for p in c_global]\n",
        "                sum_w = 0.0\n",
        "                for (cid, res), w in zip(clean, weights):\n",
        "                    new_ci = res.get(\"ci\", None)\n",
        "                    prev_ci = old_ci.get(cid, None)\n",
        "                    if new_ci is None or prev_ci is None:\n",
        "                        continue\n",
        "                    for j, (n, o) in enumerate(zip(new_ci, prev_ci)):\n",
        "                        sum_delta[j].add_((n.to(device) - o.to(device)), alpha=w)\n",
        "                    sum_w += w\n",
        "                if sum_w > 0:\n",
        "                    for j in range(len(c_global)):\n",
        "                        c_global[j].add_(sum_delta[j])  # weights already normalized to 1\n",
        "                else:\n",
        "                    print(\"[Server] SCAFFOLD: no valid weighted Δci; c_global unchanged\")\n",
        "\n",
        "\n",
        "        # optional diagnostics\n",
        "        if strategy.lower() == \"scaffold\":\n",
        "            with torch.no_grad():\n",
        "                max_ci = max(float(torch.max(torch.abs(t))) for _, r in clean for t in r.get(\"ci\", []))\n",
        "                max_cg = max(float(torch.max(torch.abs(t))) for t in c_global)\n",
        "                # print(f\"[Diag] r{rnd:03d} | max|ci|={max_ci:.3f} | max|c|={max_cg:.3f}\")\n",
        "\n",
        "        # eval\n",
        "        acc, loss = evaluate(global_model, test_loader, device)\n",
        "        acc, loss = evaluate(global_model, test_loader, device)\n",
        "        print(f\"Round {rnd:03d} | clients {len(clean):02d}/{num_clients} | drift {drift_val:.3f} | acc {acc*100:.2f}% | loss {loss:.4f} | lr {lr_r:.4g}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cgY5T2WXUyAt"
      },
      "id": "cgY5T2WXUyAt",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Setup: helpers, logging, and parser (run this once) ====\n",
        "import io, sys, os, re, time, json, shutil\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assumes a function run(**kwargs) is already defined in another cell.\n",
        "\n",
        "OUTDIR   = \"pa4_task4_runs\"   # root for artifacts\n",
        "ROUNDS   = 30                 # default rounds (consistent across methods)\n",
        "DOWNLOAD = True               # auto-download zips/plots (Colab)\n",
        "os.makedirs(OUTDIR, exist_ok=True)\n",
        "\n",
        "# Parse lines like: Round 001 | clients 10/10 | drift 3.103 | acc 33.10% | loss 2.1145\n",
        "line_re = re.compile(\n",
        "    r\"Round\\s+(\\d+)\\s+\\|\\s+clients\\s+(\\d+)\\/(\\d+)\\s+\\|\\s+drift\\s+([0-9.]+)\\s+\\|\\s+acc\\s+([0-9.]+)%\\s+\\|\\s+loss\\s+([0-9.]+)\"\n",
        ")\n",
        "\n",
        "def to_jsonable(x):\n",
        "    if isinstance(x, dict): return {str(k): to_jsonable(v) for k,v in x.items()}\n",
        "    if isinstance(x, (list, tuple)): return [to_jsonable(v) for v in x]\n",
        "    if isinstance(x, (str, int, float, bool)) or x is None: return x\n",
        "    try:\n",
        "        import numpy as np\n",
        "        if isinstance(x, np.generic): return x.item()\n",
        "    except: pass\n",
        "    try:\n",
        "        import torch\n",
        "        if isinstance(x, (torch.device, torch.dtype)): return str(x)\n",
        "    except: pass\n",
        "    return str(x)\n",
        "\n",
        "class Tee(io.TextIOBase):\n",
        "    \"\"\"Write to notebook + file simultaneously (live).\"\"\"\n",
        "    def __init__(self, file_obj, mirror): self.f, self.m = file_obj, mirror\n",
        "    def write(self, s): self.m.write(s); self.m.flush(); self.f.write(s); self.f.flush(); return len(s)\n",
        "    def flush(self): self.m.flush(); self.f.flush()\n",
        "\n",
        "def run_and_log(label: str, cfg: dict):\n",
        "    \"\"\"Runs one strategy once, prints live, saves logs/CSV/plots, and optionally zips+downloads.\"\"\"\n",
        "    stamp  = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    tag    = f\"{label}_alpha{cfg['alpha']}_K{cfg['K']}_N{cfg['num_clients']}_{stamp}\"\n",
        "    run_dir = os.path.join(OUTDIR, tag); os.makedirs(run_dir, exist_ok=True)\n",
        "\n",
        "    # Save config\n",
        "    cfg_to_save = dict(cfg); cfg_to_save[\"label\"] = label\n",
        "    with open(os.path.join(run_dir, \"config.json\"), \"w\") as f: json.dump(to_jsonable(cfg_to_save), f, indent=2)\n",
        "\n",
        "    # Live + file logging\n",
        "    log_path = os.path.join(run_dir, \"train.log\")\n",
        "    with open(log_path, \"w\") as logf:\n",
        "        old = sys.stdout; sys.stdout = Tee(logf, old)\n",
        "        try:\n",
        "            print(\"\\n\" + \"=\"*80); print(f\"Running {label}\"); print(\"=\"*80)\n",
        "            t0 = time.time()\n",
        "            run(**cfg)  # prints will appear live AND be written to train.log\n",
        "            print(f\"[{label}] elapsed: {time.time()-t0:.2f}s\")\n",
        "        finally:\n",
        "            sys.stdout = old\n",
        "\n",
        "    # Parse metrics from train.log\n",
        "    rows = []\n",
        "    with open(log_path) as f:\n",
        "        for line in f:\n",
        "            m = line_re.search(line)\n",
        "            if m:\n",
        "                rows.append((\n",
        "                    int(m.group(1)), int(m.group(2)), int(m.group(3)),\n",
        "                    float(m.group(4)), float(m.group(5))/100.0, float(m.group(6))\n",
        "                ))\n",
        "    df = pd.DataFrame(rows, columns=[\"round\",\"m_clients\",\"n_clients\",\"drift\",\"acc\",\"loss\"])\n",
        "    df.to_csv(os.path.join(run_dir, \"metrics.csv\"), index=False)\n",
        "\n",
        "    # Plots\n",
        "    if not df.empty:\n",
        "        for y, title, name in [\n",
        "            (\"acc\",  f\"{label} — Accuracy vs Rounds\", \"acc_vs_rounds.png\"),\n",
        "            (\"loss\", f\"{label} — Loss vs Rounds\",     \"loss_vs_rounds.png\"),\n",
        "            (\"drift\",f\"{label} — Drift vs Rounds\",    \"drift_vs_rounds.png\"),\n",
        "        ]:\n",
        "            plt.figure(); plt.plot(df[\"round\"], df[y]); plt.xlabel(\"Round\"); plt.ylabel(y.capitalize())\n",
        "            plt.title(title); plt.tight_layout()\n",
        "            plt.savefig(os.path.join(run_dir, name), dpi=150); plt.close()\n",
        "\n",
        "        best = df.loc[df[\"acc\"].idxmax()]\n",
        "        summary = dict(\n",
        "            final_round=int(df[\"round\"].iloc[-1]),\n",
        "            final_acc=float(df[\"acc\"].iloc[-1]),\n",
        "            best_acc=float(best[\"acc\"]),\n",
        "            best_round=int(best[\"round\"]),\n",
        "            final_loss=float(df[\"loss\"].iloc[-1]),\n",
        "            final_drift=float(df[\"drift\"].iloc[-1]),\n",
        "        )\n",
        "        with open(os.path.join(run_dir, \"summary.json\"), \"w\") as f: json.dump(summary, f, indent=2)\n",
        "        print(f\"[{label}] Final acc {summary['final_acc']:.3f} | Best {summary['best_acc']:.3f} @ r{summary['best_round']} | Drift {summary['final_drift']:.3f}\")\n",
        "    else:\n",
        "        print(f\"[{label}] WARN: no metrics parsed. Check train.log format.\")\n",
        "\n",
        "    # Zip + optional download\n",
        "    zip_path = shutil.make_archive(run_dir, \"zip\", run_dir)\n",
        "    if DOWNLOAD:\n",
        "        try:\n",
        "            from google.colab import files\n",
        "            files.download(zip_path)\n",
        "        except Exception as e:\n",
        "            print(f\"[{label}] Download skipped ({e}). Zip at: {zip_path}\")\n",
        "\n",
        "    return run_dir\n"
      ],
      "metadata": {
        "id": "PbE3HLKzkctn"
      },
      "id": "PbE3HLKzkctn",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_fedavg = dict(\n",
        "    strategy=\"fedavg\", num_clients=10, alpha=0.1, rounds=ROUNDS, K=5,\n",
        "    batch_size=64, lr=0.01, momentum=0.9, sample_frac=1.0, seed=42, mu=0.0, rho=0.0\n",
        ")\n",
        "run_dir_fedavg = run_and_log(\"FedAvg\", cfg_fedavg)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "id": "HT-t5lKZA5T6",
        "outputId": "b9e3b520-c8e7-450d-9b31-94891e721675"
      },
      "id": "HT-t5lKZA5T6",
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Running FedAvg\n",
            "================================================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170M/170M [00:04<00:00, 39.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 001 | clients 10/10 | drift 3.102 | acc 33.28% | loss 2.1141\n",
            "Round 002 | clients 10/10 | drift 3.011 | acc 41.39% | loss 1.7344\n",
            "Round 003 | clients 10/10 | drift 2.845 | acc 49.08% | loss 1.4711\n",
            "Round 004 | clients 10/10 | drift 2.727 | acc 54.18% | loss 1.3075\n",
            "Round 005 | clients 10/10 | drift 2.688 | acc 58.09% | loss 1.2105\n",
            "Round 006 | clients 10/10 | drift 2.699 | acc 61.17% | loss 1.1045\n",
            "Round 007 | clients 10/10 | drift 2.673 | acc 63.22% | loss 1.0543\n",
            "Round 008 | clients 10/10 | drift 2.683 | acc 63.94% | loss 1.0244\n",
            "Round 009 | clients 10/10 | drift 2.690 | acc 66.43% | loss 0.9715\n",
            "Round 010 | clients 10/10 | drift 2.720 | acc 67.80% | loss 0.9347\n",
            "Round 011 | clients 10/10 | drift 2.751 | acc 68.05% | loss 0.9231\n",
            "Round 012 | clients 10/10 | drift 2.771 | acc 69.02% | loss 0.8916\n",
            "Round 013 | clients 10/10 | drift 2.832 | acc 69.10% | loss 0.9054\n",
            "Round 014 | clients 10/10 | drift 2.804 | acc 70.24% | loss 0.8656\n",
            "Round 015 | clients 10/10 | drift 2.844 | acc 70.40% | loss 0.8669\n",
            "Round 016 | clients 10/10 | drift 2.844 | acc 70.90% | loss 0.8423\n",
            "Round 017 | clients 10/10 | drift 2.953 | acc 70.98% | loss 0.8397\n",
            "Round 018 | clients 10/10 | drift 2.917 | acc 71.38% | loss 0.8251\n",
            "Round 019 | clients 10/10 | drift 2.955 | acc 71.95% | loss 0.8238\n",
            "Round 020 | clients 10/10 | drift 2.998 | acc 71.62% | loss 0.8235\n",
            "Round 021 | clients 10/10 | drift 2.998 | acc 72.20% | loss 0.8113\n",
            "Round 022 | clients 10/10 | drift 3.047 | acc 72.04% | loss 0.8157\n",
            "Round 023 | clients 10/10 | drift 3.057 | acc 72.42% | loss 0.8102\n",
            "Round 024 | clients 10/10 | drift 3.072 | acc 71.85% | loss 0.8362\n",
            "Round 025 | clients 10/10 | drift 3.094 | acc 72.50% | loss 0.8184\n",
            "Round 026 | clients 10/10 | drift 3.153 | acc 73.05% | loss 0.8056\n",
            "Round 027 | clients 10/10 | drift 3.104 | acc 72.69% | loss 0.8204\n",
            "Round 028 | clients 10/10 | drift 3.169 | acc 72.82% | loss 0.8130\n",
            "Round 029 | clients 10/10 | drift 3.209 | acc 73.11% | loss 0.8170\n",
            "Round 030 | clients 10/10 | drift 3.203 | acc 73.26% | loss 0.8062\n",
            "[FedAvg] elapsed: 2759.46s\n",
            "[FedAvg] Final acc 0.733 | Best 0.733 @ r30 | Drift 3.203\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f030e813-38fd-4d36-99b7-56ec4ddd6392\", \"FedAvg_alpha0.1_K5_N10_20251110-131931.zip\", 106521)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_fedprox = dict(\n",
        "    strategy=\"fedprox\", num_clients=10, alpha=0.1, rounds=ROUNDS, K=5,\n",
        "    batch_size=64, lr=0.01, momentum=0.9, sample_frac=1.0, seed=42, mu=0.01, rho=0.0\n",
        ")\n",
        "run_dir_fedprox = run_and_log(\"FedProx\", cfg_fedprox)\n"
      ],
      "metadata": {
        "id": "etP2jqG5Q3nx",
        "outputId": "7a9008c1-2cf1-4b09-efb1-18eeb33494e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        }
      },
      "id": "etP2jqG5Q3nx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "Running FedProx\n",
            "================================================================================\n",
            "Round 001 | clients 10/10 | drift 2.646 | acc 36.54% | loss 2.1058\n",
            "Round 002 | clients 10/10 | drift 2.557 | acc 40.36% | loss 1.7754\n",
            "Round 003 | clients 10/10 | drift 2.403 | acc 47.97% | loss 1.5187\n",
            "Round 004 | clients 10/10 | drift 2.282 | acc 52.74% | loss 1.3620\n",
            "Round 005 | clients 10/10 | drift 2.239 | acc 56.20% | loss 1.2667\n",
            "Round 006 | clients 10/10 | drift 2.234 | acc 58.99% | loss 1.1704\n",
            "Round 007 | clients 10/10 | drift 2.212 | acc 61.29% | loss 1.1128\n",
            "Round 008 | clients 10/10 | drift 2.207 | acc 61.46% | loss 1.0938\n",
            "Round 009 | clients 10/10 | drift 2.206 | acc 64.04% | loss 1.0246\n",
            "Round 010 | clients 10/10 | drift 2.233 | acc 65.20% | loss 0.9969\n",
            "Round 011 | clients 10/10 | drift 2.247 | acc 66.69% | loss 0.9459\n",
            "Round 012 | clients 10/10 | drift 2.261 | acc 67.28% | loss 0.9299\n",
            "Round 013 | clients 10/10 | drift 2.304 | acc 68.13% | loss 0.9209\n",
            "Round 014 | clients 10/10 | drift 2.282 | acc 69.29% | loss 0.8891\n",
            "Round 015 | clients 10/10 | drift 2.298 | acc 69.52% | loss 0.8799\n",
            "Round 016 | clients 10/10 | drift 2.287 | acc 70.04% | loss 0.8556\n",
            "Round 017 | clients 10/10 | drift 2.368 | acc 70.58% | loss 0.8532\n",
            "Round 018 | clients 10/10 | drift 2.346 | acc 70.97% | loss 0.8344\n",
            "Round 019 | clients 10/10 | drift 2.396 | acc 71.75% | loss 0.8275\n",
            "Round 020 | clients 10/10 | drift 2.410 | acc 71.61% | loss 0.8193\n",
            "Round 021 | clients 10/10 | drift 2.411 | acc 71.48% | loss 0.8211\n",
            "Round 022 | clients 10/10 | drift 2.446 | acc 72.16% | loss 0.8074\n",
            "Round 023 | clients 10/10 | drift 2.451 | acc 72.52% | loss 0.7948\n",
            "Round 024 | clients 10/10 | drift 2.469 | acc 72.31% | loss 0.8015\n",
            "Round 025 | clients 10/10 | drift 2.481 | acc 72.37% | loss 0.8031\n",
            "Round 026 | clients 10/10 | drift 2.528 | acc 72.91% | loss 0.7887\n",
            "Round 027 | clients 10/10 | drift 2.511 | acc 73.18% | loss 0.7927\n",
            "Round 028 | clients 10/10 | drift 2.538 | acc 73.00% | loss 0.7963\n",
            "Round 029 | clients 10/10 | drift 2.561 | acc 73.33% | loss 0.7867\n",
            "Round 030 | clients 10/10 | drift 2.575 | acc 73.66% | loss 0.7746\n",
            "[FedProx] elapsed: 2944.19s\n",
            "[FedProx] Final acc 0.737 | Best 0.737 @ r30 | Drift 2.575\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_105a990d-2363-4360-8874-dc7850bfbffd\", \"FedProx_alpha0.1_K5_N10_20251110-140531.zip\", 105481)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_scaffold = dict(\n",
        "    strategy=\"scaffold\",\n",
        "    num_clients=10, alpha=0.1, rounds=ROUNDS, K=5,\n",
        "    batch_size=64, lr=0.01, momentum=0.0, sample_frac=1.0,\n",
        "    seed=42, mu=0.0, rho=0.0\n",
        ")\n",
        "run_dir_scaffold = run_and_log(\"SCAFFOLD\", cfg_scaffold)\n"
      ],
      "metadata": {
        "id": "VutWgizf644d",
        "outputId": "9075cde8-5030-4f71-c884-4ce2be40cd98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "VutWgizf644d",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "Running SCAFFOLD\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- FedGH ----\n",
        "cfg_fedgh = dict(\n",
        "    strategy=\"fedgh\",\n",
        "    num_clients=10, alpha=0.1,\n",
        "    rounds=30, K=5,\n",
        "    batch_size=64,\n",
        "    lr=0.01, momentum=0.9,\n",
        "    sample_frac=1.0,\n",
        "    seed=42,\n",
        "    mu=0.0,\n",
        "    rho=0.0,\n",
        ")\n",
        "run_dir_fedgh = run_and_log(\"FedGH\", cfg_fedgh)\n"
      ],
      "metadata": {
        "id": "4CYPzScEGznI",
        "outputId": "67a413ef-8e41-47d2-be3e-65a0475989a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        }
      },
      "id": "4CYPzScEGznI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "Running FedGH\n",
            "================================================================================\n",
            "Round 001 | clients 10/10 | drift 3.103 | acc 35.07% | loss 2.1128\n",
            "Round 002 | clients 10/10 | drift 2.997 | acc 42.38% | loss 1.7239\n",
            "Round 003 | clients 10/10 | drift 2.839 | acc 51.55% | loss 1.4488\n",
            "Round 004 | clients 10/10 | drift 2.699 | acc 54.78% | loss 1.2952\n",
            "Round 005 | clients 10/10 | drift 2.662 | acc 58.30% | loss 1.1986\n",
            "Round 006 | clients 10/10 | drift 2.649 | acc 61.65% | loss 1.0943\n",
            "Round 007 | clients 10/10 | drift 2.643 | acc 63.10% | loss 1.0568\n",
            "Round 008 | clients 10/10 | drift 2.659 | acc 64.11% | loss 1.0239\n",
            "Round 009 | clients 10/10 | drift 2.667 | acc 66.87% | loss 0.9669\n",
            "Round 010 | clients 10/10 | drift 2.688 | acc 67.93% | loss 0.9304\n",
            "Round 011 | clients 10/10 | drift 2.731 | acc 69.45% | loss 0.8851\n",
            "Round 012 | clients 10/10 | drift 2.749 | acc 69.61% | loss 0.8805\n",
            "Round 013 | clients 10/10 | drift 2.785 | acc 69.22% | loss 0.9047\n",
            "Round 014 | clients 10/10 | drift 2.789 | acc 70.87% | loss 0.8423\n",
            "Round 015 | clients 10/10 | drift 2.829 | acc 70.64% | loss 0.8611\n",
            "Round 016 | clients 10/10 | drift 2.818 | acc 71.21% | loss 0.8396\n",
            "Round 017 | clients 10/10 | drift 2.917 | acc 71.23% | loss 0.8404\n",
            "Round 018 | clients 10/10 | drift 2.894 | acc 72.05% | loss 0.8055\n",
            "Round 019 | clients 10/10 | drift 2.953 | acc 71.19% | loss 0.8448\n",
            "Round 020 | clients 10/10 | drift 2.973 | acc 72.09% | loss 0.8097\n",
            "Round 021 | clients 10/10 | drift 2.992 | acc 72.08% | loss 0.8224\n",
            "Round 022 | clients 10/10 | drift 3.055 | acc 72.64% | loss 0.7931\n",
            "Round 023 | clients 10/10 | drift 3.032 | acc 72.83% | loss 0.8033\n",
            "Round 024 | clients 10/10 | drift 3.077 | acc 72.20% | loss 0.8251\n",
            "Round 025 | clients 10/10 | drift 3.076 | acc 72.99% | loss 0.8007\n",
            "Round 026 | clients 10/10 | drift 3.145 | acc 72.74% | loss 0.8167\n",
            "Round 027 | clients 10/10 | drift 3.082 | acc 72.29% | loss 0.8281\n",
            "Round 028 | clients 10/10 | drift 3.126 | acc 72.72% | loss 0.8165\n",
            "Round 029 | clients 10/10 | drift 3.152 | acc 73.14% | loss 0.8153\n",
            "Round 030 | clients 10/10 | drift 3.195 | acc 72.90% | loss 0.8158\n",
            "[FedGH] elapsed: 2896.23s\n",
            "[FedGH] Final acc 0.729 | Best 0.731 @ r29 | Drift 3.195\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b924eb81-2e75-471a-a345-27f991a35f34\", \"FedGH_alpha0.1_K5_N10_20251111-181039.zip\", 108337)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- FedSAM ----\n",
        "cfg_fedsam = dict(\n",
        "    strategy=\"fedsam\",\n",
        "    num_clients=10, alpha=0.1,\n",
        "    rounds=30, K=5,\n",
        "    batch_size=64,\n",
        "    lr=0.01, momentum=0.9,\n",
        "    sample_frac=1.0,\n",
        "    seed=42,\n",
        "    mu=0.0,\n",
        "    rho=0.05,  # try 0.03–0.08; lower if noisy, higher if underfitting\n",
        ")\n",
        "run_dir_fedsam = run_and_log(\"FedSAM\", cfg_fedsam)\n"
      ],
      "metadata": {
        "id": "2OMJdjjpIvNk",
        "outputId": "661ca508-d992-481d-9c3a-280b4fbf479c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "2OMJdjjpIvNk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "Running FedSAM\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# combined accuracy plot\n",
        "if all_curves:\n",
        "    comb = pd.concat(all_curves, ignore_index=True)\n",
        "    plt.figure()\n",
        "    for label, grp in comb.groupby(\"label\"):\n",
        "        plt.plot(grp[\"round\"], grp[\"acc\"], label=label)\n",
        "    plt.xlabel(\"Round\"); plt.ylabel(\"Accuracy\")\n",
        "    plt.title(f\"Accuracy vs Rounds — All Strategies ({common_cfg['rounds']} rounds)\")\n",
        "    plt.legend(); plt.tight_layout()\n",
        "    combo_path = os.path.join(OUTDIR, f\"combined_accuracy_{common_cfg['rounds']}r.png\")\n",
        "    plt.savefig(combo_path, dpi=160); plt.close()\n",
        "    print(f\"Combined accuracy plot saved -> {combo_path}\")\n",
        "\n",
        "print(f\"All artifacts under: {os.path.abspath(OUTDIR)}\")"
      ],
      "metadata": {
        "id": "MXtiPYhkA4UJ"
      },
      "id": "MXtiPYhkA4UJ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}